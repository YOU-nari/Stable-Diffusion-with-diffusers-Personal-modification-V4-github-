{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOU-nari/Stable-Diffusion-with-diffusers-Personal-modification-V4-github-/blob/main/stable_diffusion_with_diffusers_personal_modification_V4.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pythonのバージョンを上げたい時だけ実行\n",
        "\n",
        "※現状は実行すると動かなくなる。\n",
        "\n",
        "将来使うかもしれないので一応追加しておく"
      ],
      "metadata": {
        "id": "odHVwbiCa0qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OSのバージョン確認\n",
        "!lsb_release -a"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xdqm5_4_PGFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonのバージョン・パス確認\n",
        "!echo $PYTHONPATH\n",
        "!python --version"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cyNINCcoP3pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 使いたいPythonのバージョンを指定\n",
        "targetPy:str=\"3.9\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "dzNPgYmsQPYi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaのインストール\n",
        "\n",
        "#@markdown [Minicondaのダウンロードページ](https://docs.conda.io/en/latest/miniconda.html)に行き、Linux用のインストーラの名前とURLを確認しておく。\n",
        "\n",
        "#@markdown 以下のセルに以下のように記載する（**空白厳禁**）\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown - `MINOCONDA_INSTALLER`=`shファイル名`　（とりあえず、最新版）\n",
        "#@markdown - `MINICONDA_DOWNLOAD_HP`=`URL`\n",
        "\n",
        "#@markdown （最終確認：2021/7/3）\n",
        "%%bash\n",
        "MINICONDA_INSTALLER=Miniconda3-py39_4.12.0-Linux-x86_64.sh #@param {type:\"string\"}\n",
        "MINICONDA_DOWNLOAD_HP=https://repo.anaconda.com/miniconda #@param {type:\"string\"}\n",
        "\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget $MINICONDA_DOWNLOAD_HP/$MINICONDA_INSTALLER\n",
        "chmod +x $MINICONDA_INSTALLER\n",
        "./$MINICONDA_INSTALLER -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "eP7qf_T9Q5x4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 以下のセルを実行して`conda バージョン`が表示されたらOK\n",
        "!conda -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n_mawP3gTJNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaをアップデート\n",
        "%%bash\n",
        "conda init bash\n",
        "conda update -n base -c defaults conda -y"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L3OQSsqIUaBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonのバージョンを変更と確認\n",
        "!conda install python=$targetPy -y\n",
        "!python -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lNe9bX7SVuZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title インポートモジュールを検索させるために`sys.path`へパスを追加\n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python\"+targetPy+\"/site-packages\")\n",
        "sys.path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cW_OMoX5V86X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここまで"
      ],
      "metadata": {
        "id": "eWv5VLqzhbE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title colaboの残り時間確認\n",
        "!cat /proc/uptime | awk '{printf(\"残り時間 : %.2f\", 12-$1/60/60)}'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z0RjMtSqhiUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpvjXRDm_QQq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 利用可能なGPUとVRAMの確認\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PJ33S-Ktra"
      },
      "source": [
        "↑GPUが動く事確認\n",
        "もし動いてない場合は ランタイムのタイプをGPUに変更\n",
        "\n",
        "**現時点最新Version**\n",
        "diffusion:2.1\n",
        "diffuser:0.9.0\n",
        "Waifu:1.3\n",
        "trinart:v2\n",
        "\n",
        "2022/12/08に<font color=\"Red\">SD2.1</font>がリリース  \n",
        "custompipelineにも対応している。\n",
        "やっとまともに使えそう。\n",
        "\n",
        "~現時点だとSD2.0はうまく動かない。~\n",
        "~なんか、色々バギーである。~\n",
        "~1.5を動かしてから2.0のモデルを読み込むと途中でコケるが使えるようにはなる。~\n",
        "~でも、微妙。修正待ちかな。 ~ \n",
        "~diffusersあたりが対応するだろ(・д・)ﾁｯ~\n",
        "~2022/11/26~\n",
        "~diffusers 0.9.0で対応したっぽいがcustompipelineが追いついてない感じがする~"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title HuggingFace🤗にログイン\n",
        "\n",
        "#markdown  https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "#from huggingface_hub import notebook_login\n",
        "#notebook_login()"
      ],
      "metadata": {
        "id": "ps9nDqIAWyxQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQEwlgJXKHmE",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion diffusersをロード\n",
        "!pip3 install diffusers[torch]==0.9 --quiet\n",
        "!pip3 install -upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy triton ftfy --quiet\n",
        "\n",
        "# xformersのインストール (T4 / P100用)\n",
        "!pip install https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl --quiet\n",
        "\n",
        "# pythonとか\n",
        "!pip3 install pytorch_lightning --quiet\n",
        "!pip3 install triton --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 必要なmodule等のダウンロードと読み込み\n",
        "\n",
        "#from transformers import CLIPTokenizer ,CLIPTextModel\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import AutoencoderKL , UNet2DConditionModel , StableDiffusionPipeline\n",
        "\n",
        "#SEEDをランダム化したいので追加\n",
        "import random\n",
        "\n",
        "#ガベージコレクション用\n",
        "import gc"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZuQWrco6lPr2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title モデルを選ぶ\n",
        "\n",
        "#@markdown Stable Diffusionモデルを選択\n",
        "\n",
        "#@markdown - SD1.5\n",
        "#@markdown - SD2.1\n",
        "#@markdown - ~Waife~\n",
        "#@markdown - Trinart\n",
        "#@markdown - Trinart-Waife-50-50\n",
        "\n",
        "#@markdown から選択\n",
        "#model = \"Stable Diffusion\" #param [\"\",\"Stable Diffusion\",\"Waifu Diffusion\",\"Trinart Stable Diffusion\",\"Trinart Waifu Stable Diffusion 50-50\"]\n",
        "\n",
        "model = \"Stable Diffusion 2.1\" #@param [\"\",\"Stable Diffusion\",\"Stable Diffusion 2.1\",\"Trinart Stable Diffusion\",\"Trinart Waifu Stable Diffusion 50-50\"]\n",
        "#@markdown `Waifuは単独処理に変更`"
      ],
      "metadata": {
        "id": "YWScX9Qcmgx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title スケジューラの選択\n",
        "#@markdown ただし、DDPM,KarrasVeは画像出力処理が必要なのかパラメータを個別設定しないといけないのか知らんけど動かない\n",
        "use_schedulers = \"DPMSolverMultistepScheduler\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"KarrasVeScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\"]\n",
        "#use_scheduler 将来使うかも? schedulerの指定用変数にするつもり\n",
        "#!kill -9 $(lsof -t)\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "if model == \"Stable Diffusion\":\n",
        " model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "#elif model == \"Waifu Diffusion\":\n",
        "# model_id = \"hakurei/waifu-diffusion\"\n",
        "# revision = \"fp32\"\n",
        "# torch_dtype = torch.float32\n",
        "elif model == \"Trinart Stable Diffusion\":\n",
        " model_id = \"naclbit/trinart_stable_diffusion_v2\"\n",
        " torch_dtype = torch.float16\n",
        " revision=\"diffusers-60k\"\n",
        "elif model == \"Trinart Waifu Stable Diffusion 50-50\":\n",
        " model_id = \"doohickey/trinart-waifu-diffusion-50-50\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "elif model == \"Stable Diffusion 2.1\":\n",
        " model_id = \"stabilityai/stable-diffusion-2-1\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
        "\n",
        "#トークナイズとテキストのエンコード用に、tokenizerと、text_encoderを読み込た\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
        "\n",
        "# モデルをGPUへ移す\n",
        "vae = vae.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")\n",
        "\n",
        "# ノイズスケジューラの指定\n",
        "if use_schedulers == \"DDIMScheduler\":\n",
        " from diffusers import DDIMScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"DDPMScheduler\":\n",
        " from diffusers import DDPMScheduler \n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"KarrasVeScheduler\":\n",
        " from  diffusers import KarrasVeScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = KarrasVeScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"LMSDiscreteScheduler\":\n",
        " from  diffusers import LMSDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"EulerDiscreteScheduler\":\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"EulerAncestralDiscreteScheduler\":\n",
        " from  diffusers import EulerAncestralDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"DPMSolverMultistepScheduler\":\n",
        " from  diffusers import DPMSolverMultistepScheduler \n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "pipe.safety_checker=None\n",
        "#↓xformersを無効にしたい場合は有効コマンドをコメントアウトして実行    \n",
        "# pipe.disable_xformers_memory_efficient_attention()"
      ],
      "metadata": {
        "id": "Q0V08cQPSkk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NSFW回避,省メモリ化,xformers有効化※SD1.5まで\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "#↓xformersを無効にしたい場合は有効コマンドをコメントアウトして実行    \n",
        "# pipe.disable_xformers_memory_efficient_attention"
      ],
      "metadata": {
        "id": "5FVy18G2Avxa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8tPqDxHJX9i"
      },
      "outputs": [],
      "source": [
        "#@title 変数の設定\n",
        "\n",
        "#変数宣言\n",
        "num_inference_steps = 50     #@param {type:\"number\"}      # Number of denoising steps\n",
        "guidance_scale = 12        #@param {type:\"number\"}       # Scale for classifier-free guidance\n",
        "#batch_size = 2 #@param {type:\"number\"}\n",
        "# 画像のサイズ 512*512が初期値\n",
        "height = 768        #@param {type:\"number\"}              # default height of Stable Diffusion\n",
        "width = 768             #@param {type:\"number\"}          # default width of Stable Diffusion\n",
        "#batch_size = 1 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 描画指示\n",
        "\n",
        "#入力文字 ここに好きな禁則文字をいれてください\n",
        "\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#ネガティブ 除外したい要素を入れる\n",
        "\n",
        "negative_prompt = \"\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "gwE8DaQ24Z0M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j8-Yu00JGMA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 画像生成回数とSEEDの種別\n",
        "print(\"SCHEDULER =\",use_schedulers)\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'}\n",
        "for i in range(N):\n",
        "# SEED値、ここをかえると 同じ入力文字でも別の画像がでます\n",
        "# seedを固定する時はseed_fixにチェック\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=20,generator = generator).images[0]\n",
        "    \n",
        "#どのSEED値で描画されたか確認用\n",
        "    print(\"SEED =\",seed)\n",
        "#どのschedulerを使ったか\n",
        "    #print(\"SCHEDULER =\",use_schedulers)\n",
        "    display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06TWdF3JQaA"
      },
      "source": [
        "もっと詳しく知りたい人は\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb#scrollTo=zHkHsdtnry57\n",
        "こっちのちゃんとしたcolabを見るんだ！！！！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhfQ4GLv39K3"
      },
      "source": [
        "# **↓Waifu単独動作**\n",
        "現状Waifuだけmodel引数にrevisionが無くて面倒くさいので独立させた。  \n",
        "ここから動かせば良い。\n",
        "特に2次元はWifuが圧倒的  \n",
        "~※NAIには当然叶わない~  \n",
        "初期のschedulerは推奨のLMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye_11709e3Y0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " #@title Waifu Diffusionのダウンロードと設定\n",
        "!pip install diffusers[torch]==0.9\n",
        "!pip install --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy triton ftfy\n",
        "\n",
        "# xformersのインストール (T4 / P100用)\n",
        "!pip install https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "# パッケージのインストール\n",
        "#!pip install diffusers[torch]==0.9 transformers\n",
        "!pip install --upgrade --pre triton\n",
        "#トークナイズとテキストのエンコード用に、tokenizerと、text_encoderを読み込む\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from diffusers import AutoencoderKL , UNet2DConditionModel\n",
        "\n",
        "from torch import autocast\n",
        "#from diffusers import DiffusionPipeline\n",
        " from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionパイプラインの準備\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\n",
        "#  \"hakurei/waifu-diffusion\",\n",
        "#  torch_dtype=torch.float32,\n",
        "  #revision=\"fp16\",#←最新バージョンで廃止されてる\n",
        "  #scheduler=DDIMScheduler(\n",
        "#vae = AutoencoderKL.from_pretrained(\"waifu-diffusion-v1-4/vae/kl-f8-anime.ckpt\")←仮 1.4リリース時に確認\n",
        "vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"vae\")\n",
        "unet = UNet2DConditionModel.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"unet\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'hakurei/waifu-diffusion',   \n",
        "    custom_pipeline=\"lpw_stable_diffusion\",\n",
        "    #revision=\"fp32\",\n",
        "    torch_dtype=torch.float32,#vae=vae,\n",
        "  scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #.clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " vae = vae.to(\"cuda\")\n",
        "# text_encoder = text_encoder.to(\"cuda\")\n",
        " unet = unet.to(\"cuda\")\n",
        "#NSFW回避処理\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "#VRAM低消費※少し実行速度が落ちる\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "#↓xformersを無効にしたい場合は有効コマンドをコメントアウトして実行    \n",
        "# pipe.disable_xformers_memory_efficient_attention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title スケジューラの選択\n",
        "#@markdown ただし、DDPM,KarrasVeは画像出力処理が必要なのかパラメータを個別設定しないといけないのか知らんけど動かない\n",
        "use_schedulers = \"DPMSolverMultistepScheduler\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"KarrasVeScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\"]\n",
        "#use_scheduler 将来使うかも? schedulerの指定用変数にするつもり\n",
        "##!kill -9 $(lsof -t)\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "\n",
        "model_id = \"hakurei/waifu-diffusion\"\n",
        "#revision = \"fp32\"\n",
        "torch_dtype = torch.float32\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
        "\n",
        "#トークナイズとテキストのエンコード用に、tokenizerと、text_encoderを読み込た\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
        "\n",
        "# モデルをGPUへ移す\n",
        "vae = vae.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")\n",
        "\n",
        "# ノイズスケジューラの指定\n",
        "if use_schedulers == \"DDIMScheduler\":\n",
        " from  diffusers import DDIMScheduler\n",
        " scheduler = DDIMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DDPMScheduler\":\n",
        " from  diffusers import DDPMScheduler\n",
        " scheduler = DDPMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"KarrasVeScheduler\":\n",
        " from  diffusers import KarrasVeScheduler\n",
        " scheduler = KarrasVeScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"LMSDiscreteScheduler\":\n",
        " from  diffusers import LMSDiscreteScheduler\n",
        " scheduler = LMSDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerAncestralDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerAncestralDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DPMSolverMultistepScheduler\":\n",
        " from  diffusers import DPMSolverMultistepScheduler\n",
        " scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# モデルをGPUへ移す\n",
        "#vae = vae.to(\"cuda\")\n",
        "#text_encoder = text_encoder.to(\"cuda\")\n",
        "#unet = unet.to(\"cuda\")\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "#↓xformersを無効にしたい場合は有効コマンドをコメントアウトして実行    \n",
        "# pipe.disable_xformers_memory_efficient_attention"
      ],
      "metadata": {
        "id": "pDx_qVEDrmLw",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTIRKLa_yfl"
      },
      "source": [
        "GUIでなくCUIで動くように直した。\n",
        "ループ組んで指定した回数実行し続けるのでこっちのほうが使い勝手よい。\n",
        "ランタイム切断でも再起動後継続する。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_inference_stepsは1~200\n",
        "\n",
        "回数が多い程綺麗になるが、極端に大きくしても変わらない\n",
        "\n",
        "推奨値は50\n",
        "\n",
        "guidance_scaleは1~20\n",
        "\n",
        "数値が大きい程Prompt内容に近くなるが多様性が無くなる\n",
        "\n",
        "推奨値は7〜8.5くらい、30超えると破綻する\n",
        "\n",
        "batch_size 増やすと施行数が増える?\n",
        "\n",
        "実行速度も上がるがVRAMを大量に消費\n",
        "\n",
        "基本的には512×512が1番良い結果が出る\n",
        "\n",
        "guidance_scale 1~30 大きい程promptに近い画像になるが多様性は無くなる"
      ],
      "metadata": {
        "id": "YDOetnwC1w1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 変数の設定\n",
        "\n",
        "#変数 初期値 512*512 scale:6 step:50\n",
        "height = 768 #@param {type:\"number\"}\n",
        "width = 768 #@param {type:\"number\"}\n",
        "guidance_scale = 12 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "#batch_size = 1 #@param {type:\"number\"}\n",
        "#num_samples = 1 これは [prompt] * num_samplesで入れ子に指定回数分出力"
      ],
      "metadata": {
        "id": "gPL1RDhR0X_8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 描画指示\n",
        "prompt = \"cute cat ear maid\" #@param {type:\"string\"}\n",
        "\n",
        "negative_prompt = \"ugly,poorly drawn,bad anatomy,muted hand and fingers,\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "LdLCkaac0sN_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dc8wK6oTpRt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "2#@title ループ回数Nとシードを設定し描画指示\n",
        "N = 1 #@param {type:\"number\"} \n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'} \n",
        "slice_size = \"\"\n",
        "#ループ処理\n",
        "for i in range(N):\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "     images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=20,generator = generator).images[0]\n",
        "\n",
        "#どのSEED値で描画されたか確認用\n",
        "     print(\"SEED =\",seed)\n",
        "     display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gdriveからモデルデータを読込できるようにしたい\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!python -m venv .env\n",
        "\n",
        "!source .env/bin/activate\n",
        "\n",
        "!pip install diffusers==0.7.1 transformers scipy ftfy accelerate\n",
        "!pip install --upgrade diffusers transformers scipy\n",
        "#!huggingface-cli login\n",
        "import torch\n",
        "from torch import autocast\n",
        "# secretAI\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "\n",
        "euler_ancestral_scheduler = EulerAncestralDiscreteScheduler.from_config(\"content/drive/MyDrive/model/novelAI.ckpt\", subfolder=\"scheduler\")\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    \"content/drive/MyDrive/model/novelAI.ckpt\",torch_dtype=torch.float16, custom_pipeline=\"lpw_stable_diffusion\", scheduler=euler_scheduler, use_auth_token=YOUR_TOKEN,\n",
        ")\n",
        "pipeline.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Z5cLeoAiY_fr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}