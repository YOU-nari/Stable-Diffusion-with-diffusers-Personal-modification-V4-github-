{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YOU-nari/Stable-Diffusion-with-diffusers-Personal-modification-V4-github-/blob/main/stable_diffusion_with_ğŸ§¨_diffusers_personal_modification_V4_3.ipynb)"
      ],
      "metadata": {
        "id": "XGLwzGNyjIcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä¸Šã’ãŸã„æ™‚ã ã‘å®Ÿè¡Œ\n",
        "\n",
        "â€»ç¾çŠ¶ã¯å®Ÿè¡Œã™ã‚‹ã¨å‹•ã‹ãªããªã‚‹ã€‚\n",
        "\n",
        "å°†æ¥ä½¿ã†ã‹ã‚‚ã—ã‚Œãªã„ã®ã§ä¸€å¿œè¿½åŠ ã—ã¦ãŠã"
      ],
      "metadata": {
        "id": "odHVwbiCa0qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OSã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª\n",
        "!lsb_release -a"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xdqm5_4_PGFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ‘ã‚¹ç¢ºèª\n",
        "!echo $PYTHONPATH\n",
        "!python --version"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cyNINCcoP3pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä½¿ã„ãŸã„Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®š\n",
        "targetPy:str=\"3.9\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "dzNPgYmsQPYi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "\n",
        "#@markdown [Minicondaã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸](https://docs.conda.io/en/latest/miniconda.html)ã«è¡Œãã€Linuxç”¨ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ã®åå‰ã¨URLã‚’ç¢ºèªã—ã¦ãŠãã€‚\n",
        "\n",
        "#@markdown ä»¥ä¸‹ã®ã‚»ãƒ«ã«ä»¥ä¸‹ã®ã‚ˆã†ã«è¨˜è¼‰ã™ã‚‹ï¼ˆ**ç©ºç™½å³ç¦**ï¼‰\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown - `MINOCONDA_INSTALLER`=`shãƒ•ã‚¡ã‚¤ãƒ«å`ã€€ï¼ˆã¨ã‚Šã‚ãˆãšã€æœ€æ–°ç‰ˆï¼‰\n",
        "#@markdown - `MINICONDA_DOWNLOAD_HP`=`URL`\n",
        "\n",
        "#@markdown ï¼ˆæœ€çµ‚ç¢ºèªï¼š2021/7/3ï¼‰\n",
        "%%bash\n",
        "MINICONDA_INSTALLER=Miniconda3-py39_4.12.0-Linux-x86_64.sh #@param {type:\"string\"}\n",
        "MINICONDA_DOWNLOAD_HP=https://repo.anaconda.com/miniconda #@param {type:\"string\"}\n",
        "\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget $MINICONDA_DOWNLOAD_HP/$MINICONDA_INSTALLER\n",
        "chmod +x $MINICONDA_INSTALLER\n",
        "./$MINICONDA_INSTALLER -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "id": "eP7qf_T9Q5x4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦`conda ãƒãƒ¼ã‚¸ãƒ§ãƒ³`ãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰OK\n",
        "!conda -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n_mawP3gTJNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ\n",
        "%%bash\n",
        "conda init bash\n",
        "conda update -n base -c defaults conda -y"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L3OQSsqIUaBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¤‰æ›´ã¨ç¢ºèª\n",
        "!conda install python=$targetPy -y\n",
        "!python -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lNe9bX7SVuZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ¤œç´¢ã•ã›ã‚‹ãŸã‚ã«`sys.path`ã¸ãƒ‘ã‚¹ã‚’è¿½åŠ \n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python\"+targetPy+\"/site-packages\")\n",
        "sys.path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cW_OMoX5V86X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title colaboã®æ®‹ã‚Šæ™‚é–“ç¢ºèª\n",
        "!cat /proc/uptime | awk '{printf(\"æ®‹ã‚Šæ™‚é–“ : %.2f\", 12-$1/60/60)}'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z0RjMtSqhiUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpvjXRDm_QQq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title åˆ©ç”¨å¯èƒ½ãªGPUã¨VRAMã®ç¢ºèª\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ã“ã“ã‹ã‚‰<font color=\"Red\">Diffusers!</font>**"
      ],
      "metadata": {
        "id": "fR0ST3WubFZW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PJ33S-Ktra"
      },
      "source": [
        "â†‘GPUãŒå‹•ãäº‹ç¢ºèª\n",
        "ã‚‚ã—å‹•ã„ã¦ãªã„å ´åˆã¯ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’GPUã«å¤‰æ›´\n",
        "\n",
        "**ç¾æ™‚ç‚¹æœ€æ–°Version**\n",
        "diffusion:2.1\n",
        "diffuser:0.9.0\n",
        "Waifu:1.3\n",
        "trinart:v2\n",
        "\n",
        "2022/12/08ã«<font color=\"Red\">SD2.1</font>ãŒãƒªãƒªãƒ¼ã‚¹  \n",
        "custompipelineã«ã‚‚å¯¾å¿œã—ã¦ã„ã‚‹ã€‚\n",
        "ã‚„ã£ã¨ã¾ã¨ã‚‚ã«ä½¿ãˆãã†ã€‚\n",
        "\n",
        "~ç¾æ™‚ç‚¹ã ã¨SD2.0ã¯ã†ã¾ãå‹•ã‹ãªã„ã€‚~\n",
        "~ãªã‚“ã‹ã€è‰²ã€…ãƒã‚®ãƒ¼ã§ã‚ã‚‹ã€‚~\n",
        "~1.5ã‚’å‹•ã‹ã—ã¦ã‹ã‚‰2.0ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã¨é€”ä¸­ã§ã‚³ã‚±ã‚‹ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ã¯ãªã‚‹ã€‚~\n",
        "~ã§ã‚‚ã€å¾®å¦™ã€‚ä¿®æ­£å¾…ã¡ã‹ãªã€‚ ~ \n",
        "~diffusersã‚ãŸã‚ŠãŒå¯¾å¿œã™ã‚‹ã ã‚(ãƒ»Ğ´ãƒ»)ï¾ï½¯~\n",
        "~2022/11/26~\n",
        "~diffusers 0.9.0ã§å¯¾å¿œã—ãŸã£ã½ã„ãŒcustompipelineãŒè¿½ã„ã¤ã„ã¦ãªã„æ„Ÿã˜ãŒã™ã‚‹~"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title HuggingFaceğŸ¤—ã«ãƒ­ã‚°ã‚¤ãƒ³\n",
        "\n",
        "#markdown  https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "#from huggingface_hub import notebook_login\n",
        "#notebook_login()"
      ],
      "metadata": {
        "id": "ps9nDqIAWyxQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQEwlgJXKHmE",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion diffusersã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "!pip3 install diffusers[torch]==0.10 --quiet\n",
        "!pip3 install --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy triton ftfy --quiet\n",
        "!pip3 install --upgrade git+https://github.com/huggingface/transformers/ --quiet\n",
        "\n",
        "# xformersã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (T4 / P100ç”¨)\n",
        "!pip3 install https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl --quiet\n",
        "\n",
        "# pythonã¨ã‹\n",
        "!pip3 install pytorch_lightning --quiet\n",
        "!pip3 install triton --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title å¿…è¦ãªmoduleç­‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨èª­ã¿è¾¼ã¿\n",
        "\n",
        "#from transformers import CLIPTokenizer ,CLIPTextModel\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import AutoencoderKL , UNet2DConditionModel , StableDiffusionPipeline\n",
        "\n",
        "#SEEDã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã—ãŸã„ã®ã§è¿½åŠ \n",
        "import random"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZuQWrco6lPr2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶\n",
        "\n",
        "#@markdown Stable Diffusionãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ\n",
        "\n",
        "#@markdown - SD1.5\n",
        "#@markdown - SD2.1(768*768,512*512[base])\n",
        "#@markdown - ~Waife~\n",
        "#@markdown - Trinart\n",
        "#@markdown - Trinart-Waife-50-50\n",
        "\n",
        "#@markdown ã‹ã‚‰é¸æŠ\n",
        "#model = \"Stable Diffusion\" #param [\"\",\"Stable Diffusion\",\"Waifu Diffusion\",\"Trinart Stable Diffusion\",\"Trinart Waifu Stable Diffusion 50-50\"]\n",
        "\n",
        "model = \"Stable Diffusion 2.1(base)\" #@param [\"\",\"Stable Diffusion\",\"Stable Diffusion 2.1\",\"Stable Diffusion 2.1(base)\",\"Trinart Stable Diffusion\",\"Trinart Waifu Stable Diffusion 50-50\"]\n",
        "#@markdown `Waifuã¯å˜ç‹¬å‡¦ç†ã«å¤‰æ›´`"
      ],
      "metadata": {
        "id": "YWScX9Qcmgx5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®é¸æŠ\n",
        "#@markdown ãŸã ã—ã€DDPMã¯æœ€ä½1000stepã¯å¿…è¦(é…ã„),~KarrasVeã¯ç”»åƒå‡ºåŠ›å‡¦ç†ãŒå¿…è¦ãªã®ã‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å€‹åˆ¥è¨­å®šã—ãªã„ã¨ã„ã‘ãªã„ã®ã‹çŸ¥ã‚‰ã‚“ã‘ã©å‹•ã‹ãªã„~å‹•ã‹ã›ãªã„ã®ã§ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¨ã„ãŸã€‚\n",
        "use_schedulers = \"DPMSolverMultistepScheduler\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\",\"HeunDiscreteScheduler\",\"DPMSolverSinglestepScheduler\"]\n",
        "#@markdown K-LMSD(LMSKarras)=<br>(LMSDiscreteScheduler\n",
        "#@markdown K-Euler(Euler)=EulerDiscreteScheduler\n",
        "#@markdown K-Euler Ancestral(Euler a)=<br>EulerAncestralDiscreteScheduler\n",
        "#@markdown DPM-Solver++(DPM++)=<br>DPMSolverMultistepScheduler,DPMSolversinglestepScheduler\n",
        "#@markdown ğŸ‘†DPM++ã¯Multe,Singleã®å·®ãŒã‚ã‹ã‚‰ãªã„ã¨å®Ÿè£…ã—ãŸäººãŒè¨€ã£ã¦ãŸã€‚<br>(å®Ÿè¡Œçµæœæ¯”è¼ƒç”¨ç”»åƒã‚‚å¼µã‚‰ã‚Œã¦ã„ãŸãŒç¢ºã‹ã«ã‚ã‹ã‚‰ã‚“ã€‚)\n",
        "\n",
        "#use_schedulers = \"DPMSolverMultistepScheduler\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"KarrasVeScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\",\"HeunDiscreteScheduler\",\"DPMSolverSinglestepScheduler\"]\n",
        "\n",
        "#use_scheduler å°†æ¥ä½¿ã†ã‹ã‚‚? schedulerã®æŒ‡å®šç”¨å¤‰æ•°ã«ã™ã‚‹ã¤ã‚‚ã‚Š\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "if model == \"Stable Diffusion\":\n",
        " model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "#elif model == \"Waifu Diffusion\":\n",
        "# model_id = \"hakurei/waifu-diffusion\"\n",
        "# revision = \"fp32\"\n",
        "# torch_dtype = torch.float32\n",
        "elif model == \"Trinart Stable Diffusion\":\n",
        " model_id = \"naclbit/trinart_stable_diffusion_v2\"\n",
        " torch_dtype = torch.float16\n",
        " revision=\"diffusers-60k\"\n",
        "elif model == \"Trinart Waifu Stable Diffusion 50-50\":\n",
        " model_id = \"doohickey/trinart-waifu-diffusion-50-50\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "elif model == \"Stable Diffusion 2.1\":\n",
        " model_id = \"stabilityai/stable-diffusion-2-1\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "elif model == \"Stable Diffusion 2.1(base)\":\n",
        " model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
        "\n",
        "#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ã€tokenizerã¨ã€text_encoderã‚’èª­è¾¼\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã¸ç§»ã™\n",
        "vae = vae.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")\n",
        "\n",
        "# ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®æŒ‡å®š\n",
        "if use_schedulers == \"DDIMScheduler\":\n",
        " from diffusers import DDIMScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"DDPMScheduler\":\n",
        " from diffusers import DDPMScheduler \n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        "# pipe.scheduler = DDPMScheduler(num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02, beta_schedule=\"linear\", trained_betas=None, variance_type=\"fixed_small\", clip_sample=True)\n",
        " pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"KarrasVeScheduler\":\n",
        " from  diffusers import KarrasVeScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = KarrasVeScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"LMSDiscreteScheduler\":\n",
        " from  diffusers import LMSDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"EulerDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"EulerAncestralDiscreteScheduler\":\n",
        " from  diffusers import EulerAncestralDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"DPMSolverMultistepScheduler\":\n",
        " from  diffusers import DPMSolverMultistepScheduler \n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"HeunDiscreteScheduler\":\n",
        " from diffusers import HeunDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = HeunDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DPMSolverSinglestepScheduler\":\n",
        " from diffusers import DPMSolverSinglestepScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, revision=revision, torch_dtype=torch_dtype ,safety_checker=None,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DPMSolverSinglestepScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "pipe.safety_checker=None\n",
        "#â†“xformersã‚’ç„¡åŠ¹ã«ã—ãŸã„å ´åˆã¯æœ‰åŠ¹ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦å®Ÿè¡Œ    \n",
        "# pipe.disable_xformers_memory_efficient_attention()\n",
        "print(\"Execution completed! \"+use_schedulers+\" is scheduler\")"
      ],
      "metadata": {
        "id": "Q0V08cQPSkk8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NSFWå›é¿,çœãƒ¡ãƒ¢ãƒªåŒ–,xformersæœ‰åŠ¹åŒ–â€»SD1.5ã¾ã§\n",
        "if not model == \"Stable Diffusion 2.1\":\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " pipe.enable_attention_slicing()\n",
        " pipe.enable_xformers_memory_efficient_attention()\n",
        "#â†“xformersã‚’ç„¡åŠ¹ã«ã—ãŸã„å ´åˆã¯æœ‰åŠ¹ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦å®Ÿè¡Œ    \n",
        "# pipe.disable_xformers_memory_efficient_attention\n",
        "else:\n",
        " print(\"SD2.1 You don't have to run this cell!\")"
      ],
      "metadata": {
        "id": "5FVy18G2Avxa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8tPqDxHJX9i",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title å¤‰æ•°ã®è¨­å®š\n",
        "\n",
        "#å¤‰æ•°å®£è¨€\n",
        "num_inference_steps = 25     #@param {type:\"number\"}      # Number of denoising steps\n",
        "guidance_scale = 12        #@param {type:\"number\"}       # Scale for classifier-free guidance\n",
        "#batch_size = 2 #@param {type:\"number\"}\n",
        "# ç”»åƒã®ã‚µã‚¤ã‚º 512*512ãŒåˆæœŸå€¤\n",
        "height = 512        #@param {type:\"number\"}              # default height of Stable Diffusion\n",
        "width = 512             #@param {type:\"number\"}          # default width of Stable Diffusion\n",
        "#batch_size = 1 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title æç”»æŒ‡ç¤º\n",
        "\n",
        "#å…¥åŠ›æ–‡å­— ã“ã“ã«å¥½ããªç¦å‰‡æ–‡å­—ã‚’ã„ã‚Œã¦ãã ã•ã„\n",
        "\n",
        "prompt = \"cute cat ear maid\" #@param {type:\"string\"}\n",
        "\n",
        "#ãƒã‚¬ãƒ†ã‚£ãƒ– é™¤å¤–ã—ãŸã„è¦ç´ ã‚’å…¥ã‚Œã‚‹\n",
        "\n",
        "negative_prompt = \"ugly,poorly drawn,bad anatomy,muted hand and fingers,\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "gwE8DaQ24Z0M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j8-Yu00JGMA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ç”»åƒç”Ÿæˆå›æ•°ã¨SEEDã®ç¨®åˆ¥\n",
        "print(\"SCHEDULER =\",use_schedulers)\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = True #@param {'type':'boolean'}\n",
        "for i in range(N):\n",
        "# SEEDå€¤ã€ã“ã“ã‚’ã‹ãˆã‚‹ã¨ åŒã˜å…¥åŠ›æ–‡å­—ã§ã‚‚åˆ¥ã®ç”»åƒãŒã§ã¾ã™\n",
        "# seedã‚’å›ºå®šã™ã‚‹æ™‚ã¯seed_fixã«ãƒã‚§ãƒƒã‚¯\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=8,generator = generator).images[0]\n",
        "    \n",
        "#ã©ã®SEEDå€¤ã§æç”»ã•ã‚ŒãŸã‹ç¢ºèªç”¨\n",
        "    print(\"SEED =\",seed)\n",
        "#ã©ã®schedulerã‚’ä½¿ã£ãŸã‹\n",
        "    #print(\"SCHEDULER =\",use_schedulers)\n",
        "    display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06TWdF3JQaA"
      },
      "source": [
        "ã‚‚ã£ã¨è©³ã—ãçŸ¥ã‚ŠãŸã„äººã¯\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb#scrollTo=zHkHsdtnry57\n",
        "ã“ã£ã¡ã®ã¡ã‚ƒã‚“ã¨ã—ãŸcolabã‚’è¦‹ã‚‹ã‚“ã ï¼ï¼ï¼ï¼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhfQ4GLv39K3"
      },
      "source": [
        "# **â†“Waifuå˜ç‹¬å‹•ä½œ**\n",
        "ç¾çŠ¶Waifuã ã‘modelå¼•æ•°ã«revisionãŒç„¡ãã¦é¢å€’ãã•ã„ã®ã§ç‹¬ç«‹ã•ã›ãŸã€‚  \n",
        "ã“ã“ã‹ã‚‰å‹•ã‹ã›ã°è‰¯ã„ã€‚\n",
        "ç‰¹ã«2æ¬¡å…ƒã¯WifuãŒåœ§å€’çš„  \n",
        "~â€»NAIã«ã¯å½“ç„¶å¶ã‚ãªã„~  \n",
        "**åˆæœŸã®schedulerã¯æ¨å¥¨ã®K-LMS(LMS Karras)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye_11709e3Y0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " #@title Waifu Diffusionã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è¨­å®š\n",
        "!pip3 install diffusers[torch]==0.10 --quiet\n",
        "!pip3 install --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy triton ftfy --quiet\n",
        "!pip3 install --upgrade git+https://github.com/huggingface/transformers/ --quiet\n",
        "\n",
        "# xformersã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (T4 / P100ç”¨)\n",
        "!pip3 install https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl --quiet\n",
        "\n",
        "# pythonã¨ã‹\n",
        "!pip3 install pytorch_lightning --quiet\n",
        "!pip3 install triton --quiet\n",
        "\n",
        "#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ã€tokenizerã¨ã€text_encoderã‚’èª­ã¿è¾¼ã‚€\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from diffusers import AutoencoderKL , UNet2DConditionModel\n",
        "\n",
        "from torch import autocast\n",
        "#from diffusers import DiffusionPipeline\n",
        " from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\n",
        "#  \"hakurei/waifu-diffusion\",\n",
        "#  torch_dtype=torch.float32,\n",
        "  #revision=\"fp16\",#â†æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å»ƒæ­¢ã•ã‚Œã¦ã‚‹\n",
        "  #scheduler=DDIMScheduler(\n",
        "#vae = AutoencoderKL.from_pretrained(\"waifu-diffusion-v1-4/vae/kl-f8-anime.ckpt\")â†ä»® 1.4ãƒªãƒªãƒ¼ã‚¹æ™‚ã«ç¢ºèª\n",
        "vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"vae\")\n",
        "unet = UNet2DConditionModel.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"unet\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'hakurei/waifu-diffusion',   \n",
        "    custom_pipeline=\"lpw_stable_diffusion\",\n",
        "    #revision=\"fp32\",\n",
        "    torch_dtype=torch.float32,#vae=vae,\n",
        "  scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #.clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " vae = vae.to(\"cuda\")\n",
        "# text_encoder = text_encoder.to(\"cuda\")\n",
        " unet = unet.to(\"cuda\")\n",
        "#NSFWå›é¿å‡¦ç†\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "#VRAMä½æ¶ˆè²»â€»å°‘ã—å®Ÿè¡Œé€Ÿåº¦ãŒè½ã¡ã‚‹\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "#â†“xformersã‚’ç„¡åŠ¹ã«ã—ãŸã„å ´åˆã¯æœ‰åŠ¹ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦å®Ÿè¡Œ    \n",
        "# pipe.disable_xformers_memory_efficient_attention"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®é¸æŠ\n",
        "use_schedulers = \"DPMSolverSinglestepScheduler\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\",\"HeunDiscreteScheduler\",\"DPMSolverSinglestepScheduler\"]\n",
        "#use_scheduler å°†æ¥ä½¿ã†ã‹ã‚‚? schedulerã®æŒ‡å®šç”¨å¤‰æ•°ã«ã™ã‚‹ã¤ã‚‚ã‚Š\n",
        "##!kill -9 $(lsof -t)\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "model_id = \"hakurei/waifu-diffusion\"\n",
        "#revision = \"fp32\"\n",
        "torch_dtype = torch.float32\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
        "\n",
        "#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ã€tokenizerã¨ã€text_encoderã‚’èª­ã¿è¾¼ãŸ\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã¸ç§»ã™\n",
        "vae = vae.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")\n",
        "\n",
        "# ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®æŒ‡å®š\n",
        "if use_schedulers == \"DDIMScheduler\":\n",
        " from diffusers import DDIMScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"DDPMScheduler\":\n",
        " from diffusers import DDPMScheduler \n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        "# pipe.scheduler = DDPMScheduler(num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02, beta_schedule=\"linear\", trained_betas=None, variance_type=\"fixed_small\", clip_sample=True)\n",
        " pipe.scheduler = DDPMScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"KarrasVeScheduler\":\n",
        " from  diffusers import KarrasVeScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = KarrasVeScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"LMSDiscreteScheduler\":\n",
        " from  diffusers import LMSDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = LMSDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"EulerDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"EulerAncestralDiscreteScheduler\":\n",
        " from  diffusers import EulerAncestralDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "\n",
        "elif use_schedulers == \"DPMSolverMultistepScheduler\":\n",
        " from  diffusers import DPMSolverMultistepScheduler \n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"HeunDiscreteScheduler\":\n",
        " from diffusers import HeunDiscreteScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = HeunDiscreteScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DPMSolverSinglestepScheduler\":\n",
        " from diffusers import DPMSolverSinglestepScheduler\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id,torch_dtype=torch_dtype ,safety_checker=None ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe.scheduler = DPMSolverSinglestepScheduler.from_config(pipe.scheduler.config)\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "#pipe.enable_attention_slicing()\n",
        "#pipe.enable_xformers_memory_efficient_attention()\n",
        "#pipe.safety_checker=None\n",
        "#â†“xformersã‚’ç„¡åŠ¹ã«ã—ãŸã„å ´åˆã¯æœ‰åŠ¹ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦å®Ÿè¡Œ    \n",
        "# pipe.disable_xformers_memory_efficient_attention()\n",
        "print(\"Execution completed! \"+use_schedulers+\" is scheduler\")"
      ],
      "metadata": {
        "id": "pDx_qVEDrmLw",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTIRKLa_yfl"
      },
      "source": [
        "GUIã§ãªãCUIã§å‹•ãã‚ˆã†ã«ç›´ã—ãŸã€‚\n",
        "ãƒ«ãƒ¼ãƒ—çµ„ã‚“ã§æŒ‡å®šã—ãŸå›æ•°å®Ÿè¡Œã—ç¶šã‘ã‚‹ã®ã§ã“ã£ã¡ã®ã»ã†ãŒä½¿ã„å‹æ‰‹ã‚ˆã„ã€‚\n",
        "ãƒ©ãƒ³ã‚¿ã‚¤ãƒ åˆ‡æ–­ã§ã‚‚å†èµ·å‹•å¾Œç¶™ç¶šã™ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_inference_stepsã¯1~200\n",
        "\n",
        "å›æ•°ãŒå¤šã„ç¨‹ç¶ºéº—ã«ãªã‚‹ãŒã€æ¥µç«¯ã«å¤§ããã—ã¦ã‚‚å¤‰ã‚ã‚‰ãªã„\n",
        "\n",
        "æ¨å¥¨å€¤ã¯50\n",
        "\n",
        "guidance_scaleã¯1~20\n",
        "\n",
        "æ•°å€¤ãŒå¤§ãã„ç¨‹Promptå†…å®¹ã«è¿‘ããªã‚‹ãŒå¤šæ§˜æ€§ãŒç„¡ããªã‚‹\n",
        "\n",
        "æ¨å¥¨å€¤ã¯7ã€œ8.5ãã‚‰ã„ã€30è¶…ãˆã‚‹ã¨ç ´ç¶»ã™ã‚‹\n",
        "\n",
        "batch_size å¢—ã‚„ã™ã¨æ–½è¡Œæ•°ãŒå¢—ãˆã‚‹?\n",
        "\n",
        "å®Ÿè¡Œé€Ÿåº¦ã‚‚ä¸ŠãŒã‚‹ãŒVRAMã‚’å¤§é‡ã«æ¶ˆè²»\n",
        "\n",
        "åŸºæœ¬çš„ã«ã¯512Ã—512ãŒ1ç•ªè‰¯ã„çµæœãŒå‡ºã‚‹\n",
        "\n",
        "guidance_scale 1~30 å¤§ãã„ç¨‹promptã«è¿‘ã„ç”»åƒã«ãªã‚‹ãŒå¤šæ§˜æ€§ã¯ç„¡ããªã‚‹"
      ],
      "metadata": {
        "id": "YDOetnwC1w1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title å¤‰æ•°ã®è¨­å®š\n",
        "\n",
        "#å¤‰æ•° åˆæœŸå€¤ 512*512 scale:6 step:50\n",
        "height = 512 #@param {type:\"number\"}\n",
        "width = 512 #@param {type:\"number\"}\n",
        "guidance_scale = 6 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "#batch_size = 1 #@param {type:\"number\"}\n",
        "#num_samples = 1 ã“ã‚Œã¯ [prompt] * num_samplesã§å…¥ã‚Œå­ã«æŒ‡å®šå›æ•°åˆ†å‡ºåŠ›"
      ],
      "metadata": {
        "id": "gPL1RDhR0X_8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title æç”»æŒ‡ç¤º\n",
        "prompt = \"cute cat ear maid\" #@param {type:\"string\"}\n",
        "\n",
        "negative_prompt = \"ugly,poorly drawn,bad anatomy,muted hand and fingers,\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "LdLCkaac0sN_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dc8wK6oTpRt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "2#@title ãƒ«ãƒ¼ãƒ—å›æ•°Nã¨ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—æç”»æŒ‡ç¤º\n",
        "N = 1 #@param {type:\"number\"} \n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'} \n",
        "slice_size = \"\"\n",
        "#ãƒ«ãƒ¼ãƒ—å‡¦ç†\n",
        "for i in range(N):\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "     images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=20,generator = generator).images[0]\n",
        "\n",
        "#ã©ã®SEEDå€¤ã§æç”»ã•ã‚ŒãŸã‹ç¢ºèªç”¨\n",
        "     print(\"SEED =\",seed)\n",
        "     display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gdriveã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­è¾¼ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!python -m venv .env\n",
        "\n",
        "!source .env/bin/activate\n",
        "\n",
        "!pip install diffusers==0.7.1 transformers scipy ftfy accelerate\n",
        "!pip install --upgrade diffusers transformers scipy\n",
        "#!huggingface-cli login\n",
        "import torch\n",
        "from torch import autocast\n",
        "# secretAI\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "\n",
        "euler_ancestral_scheduler = EulerAncestralDiscreteScheduler.from_config(\"content/drive/MyDrive/model/novelAI.ckpt\", subfolder=\"scheduler\")\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    \"content/drive/MyDrive/model/novelAI.ckpt\",torch_dtype=torch.float16, custom_pipeline=\"lpw_stable_diffusion\", scheduler=euler_scheduler, use_auth_token=YOUR_TOKEN,\n",
        ")\n",
        "pipeline.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Z5cLeoAiY_fr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}