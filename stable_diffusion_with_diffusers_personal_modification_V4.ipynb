{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOU-nari/Stable-Diffusion-with-diffusers-Personal-modification-V4-github-/blob/main/stable_diffusion_with_diffusers_personal_modification_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä¸Šã’ãŸã„æ™‚ã ã‘å®Ÿè¡Œ\n",
        "\n",
        "â€»ç¾çŠ¶ã¯å®Ÿè¡Œã™ã‚‹ã¨å‹•ã‹ãªããªã‚‹ã€‚\n",
        "\n",
        "å°†æ¥ä½¿ã†ã‹ã‚‚ã—ã‚Œãªã„ã®ã§ä¸€å¿œè¿½åŠ ã—ã¦ãŠã"
      ],
      "metadata": {
        "id": "odHVwbiCa0qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OSã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª\n",
        "!lsb_release -a"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xdqm5_4_PGFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒ»ãƒ‘ã‚¹ç¢ºèª\n",
        "!echo $PYTHONPATH\n",
        "!python --version"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cyNINCcoP3pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä½¿ã„ãŸã„Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æŒ‡å®š\n",
        "targetPy:str=\"3.9\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "dzNPgYmsQPYi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "\n",
        "#@markdown [Minicondaã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸](https://docs.conda.io/en/latest/miniconda.html)ã«è¡Œãã€Linuxç”¨ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ã®åå‰ã¨URLã‚’ç¢ºèªã—ã¦ãŠãã€‚\n",
        "\n",
        "#@markdown ä»¥ä¸‹ã®ã‚»ãƒ«ã«ä»¥ä¸‹ã®ã‚ˆã†ã«è¨˜è¼‰ã™ã‚‹ï¼ˆ**ç©ºç™½å³ç¦**ï¼‰\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown - `MINOCONDA_INSTALLER`=`shãƒ•ã‚¡ã‚¤ãƒ«å`ã€€ï¼ˆã¨ã‚Šã‚ãˆãšã€æœ€æ–°ç‰ˆï¼‰\n",
        "#@markdown - `MINICONDA_DOWNLOAD_HP`=`URL`\n",
        "\n",
        "#@markdown ï¼ˆæœ€çµ‚ç¢ºèªï¼š2021/7/3ï¼‰\n",
        "%%bash\n",
        "MINICONDA_INSTALLER=Miniconda3-py39_4.12.0-Linux-x86_64.sh #@param {type:\"string\"}\n",
        "MINICONDA_DOWNLOAD_HP=https://repo.anaconda.com/miniconda #@param {type:\"string\"}\n",
        "\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget $MINICONDA_DOWNLOAD_HP/$MINICONDA_INSTALLER\n",
        "chmod +x $MINICONDA_INSTALLER\n",
        "./$MINICONDA_INSTALLER -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eP7qf_T9Q5x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦`conda ãƒãƒ¼ã‚¸ãƒ§ãƒ³`ãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰OK\n",
        "!conda -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n_mawP3gTJNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaã‚’ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ\n",
        "%%bash\n",
        "conda init bash\n",
        "conda update -n base -c defaults conda -y"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L3OQSsqIUaBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¤‰æ›´ã¨ç¢ºèª\n",
        "!conda install python=$targetPy -y\n",
        "!python -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lNe9bX7SVuZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’æ¤œç´¢ã•ã›ã‚‹ãŸã‚ã«`sys.path`ã¸ãƒ‘ã‚¹ã‚’è¿½åŠ \n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python\"+targetPy+\"/site-packages\")\n",
        "sys.path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cW_OMoX5V86X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã“ã“ã¾ã§"
      ],
      "metadata": {
        "id": "eWv5VLqzhbE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title colaboã®æ®‹ã‚Šæ™‚é–“ç¢ºèª\n",
        "!cat /proc/uptime | awk '{printf(\"æ®‹ã‚Šæ™‚é–“ : %.2f\", 12-$1/60/60)}'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z0RjMtSqhiUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpvjXRDm_QQq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title åˆ©ç”¨å¯èƒ½ãªGPUã¨VRAMã®ç¢ºèª\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PJ33S-Ktra"
      },
      "source": [
        "â†‘GPUãŒå‹•ãäº‹ç¢ºèªã—ã¦ã­     \n",
        "ã‚‚ã—å‹•ã„ã¦ãªã„å ´åˆã¯ ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã®ã‚¿ã‚¤ãƒ—ã‚’GPUã«ã—ã¦ã­\n",
        "\n",
        "â†“diffusersãŒæ›´æ–°ã•ã‚ŒãŸã‚‰å¤‰æ›´ã—ã¦ã­\n",
        "ç¾æ™‚ç‚¹æœ€æ–°\n",
        "diffusion:2.0\n",
        "diffuser:0.8.1\n",
        "Waifu:1.3\n",
        "trinart:v2\n",
        "\n",
        "ç¾æ™‚ç‚¹ã ã¨SD2.0ã¯ã†ã¾ãå‹•ã‹ãªã„ã€‚\n",
        "ãªã‚“ã‹ã€è‰²ã€…ãƒã‚®ãƒ¼ã§ã‚ã‚‹ã€‚\n",
        "1.5ã‚’å‹•ã‹ã—ã¦ã‹ã‚‰2.0ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã¨é€”ä¸­ã§ã‚³ã‚±ã‚‹ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ã¯ãªã‚‹ã€‚\n",
        "ã§ã‚‚ã€å¾®å¦™ã€‚ä¿®æ­£å¾…ã¡ã‹ãªã€‚  \n",
        "~diffusersã‚ãŸã‚ŠãŒå¯¾å¿œã™ã‚‹ã ã‚(ãƒ»Ğ´ãƒ»)ï¾ï½¯~"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title HuggingFaceğŸ¤—ã«ãƒ­ã‚°ã‚¤ãƒ³\n",
        "\n",
        "#markdown  https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "#from huggingface_hub import notebook_login\n",
        "#notebook_login()"
      ],
      "metadata": {
        "id": "ps9nDqIAWyxQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQEwlgJXKHmE",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion diffusersã‚’ãƒ­ãƒ¼ãƒ‰\n",
        "\n",
        "!pip install -q diffusers==0.8.1 transformers scipy ftfy accelerate\n",
        "!pip install -q transformers scipy ftfy\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "#!pip install -q huggingface_hub\n",
        "!pip install -q --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy\n",
        "\n",
        "\n",
        "#!huggingface-cli login\n",
        "#è‡ªåˆ†ã®ãƒˆãƒ¼ã‚¯ãƒ³è¨˜è¼‰ diffuser0.4.0ã‹ã‚‰ã¯1åº¦ãƒ­ã‚°ãƒ»ã‚¤ãƒ³ã™ã‚Œã°ä¸è¦ã‚‰ã—ã„\n",
        "#YOUR_TOKEN=\"\"\n",
        "!git clone -q https://github.com/openai/triton.git\n",
        "%cd triton/python/\n",
        "!pip install -q -e .\n",
        "!pip3 install -q --upgrade triton\n",
        "!pip install -q pytorch_lightning\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title å¿…è¦ãªmoduleç­‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨èª­ã¿è¾¼ã¿\n",
        "\n",
        "#from transformers import CLIPTokenizer ,CLIPTextModel\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import AutoencoderKL , UNet2DConditionModel , StableDiffusionPipeline\n",
        "\n",
        "#SEEDã‚’ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã—ãŸã„ã®ã§è¿½åŠ \n",
        "import random\n",
        "\n",
        "#ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ç”¨\n",
        "import gc"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZuQWrco6lPr2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ãƒ¢ãƒ‡ãƒ«ã‚’é¸ã¶\n",
        "\n",
        "#@markdown Stable Diffusionãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ\n",
        "\n",
        "#@markdown Normal,Waife,Trinart,Trinart-Waife-50-50ã‹ã‚‰é¸æŠ\n",
        "model = \"\" #@param [\"\",\"Stable Diffusion\",\"Waifu Diffusion\",\"Trinart Stable Diffusion\",\"Trinart Waifu Stable Diffusion 50-50\"]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YWScX9Qcmgx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®é¸æŠ\n",
        "#@markdown ãŸã ã—ã€DDPM,KarrasVeã¯ç”»åƒå‡ºåŠ›å‡¦ç†ãŒå¿…è¦ãªã®ã‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å€‹åˆ¥è¨­å®šã—ãªã„ã¨ã„ã‘ãªã„ã®ã‹çŸ¥ã‚‰ã‚“ã‘ã©å‹•ã‹ãªã„\n",
        "use_schedulers = \"\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"KarrasVeScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\"]\n",
        "#use_scheduler å°†æ¥ä½¿ã†ã‹ã‚‚? schedulerã®æŒ‡å®šç”¨å¤‰æ•°ã«ã™ã‚‹ã¤ã‚‚ã‚Š\n",
        "#!kill -9 $(lsof -t)\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "if model == \"Stable Diffusion\":\n",
        " #model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        " model_id = \"stabilityai/stable-diffusion-2\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "elif model == \"Waifu Diffusion\":\n",
        " model_id = \"hakurei/waifu-diffusion\"\n",
        " revision = \"fp32\"\n",
        " torch_dtype = torch.float32\n",
        "elif model == \"Trinart Stable Diffusion\":\n",
        " model_id = \"naclbit/trinart_stable_diffusion_v2\"\n",
        " torch_dtype = torch.float16\n",
        " revision=\"diffusers-60k\"\n",
        "elif model == \"Trinart Waifu Stable Diffusion 50-50\":\n",
        " model_id = \"doohickey/trinart-waifu-diffusion-50-50\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
        "\n",
        "#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ã€tokenizerã¨ã€text_encoderã‚’èª­ã¿è¾¼ãŸ\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã¸ç§»ã™\n",
        "vae = vae.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")\n",
        "\n",
        "# ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®æŒ‡å®š\n",
        "if use_schedulers == \"DDIMScheduler\":\n",
        " from  diffusers import DDIMScheduler\n",
        " scheduler = DDIMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DDPMScheduler\":\n",
        " from  diffusers import DDPMScheduler\n",
        " scheduler = DDPMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"KarrasVeScheduler\":\n",
        " from  diffusers import KarrasVeScheduler\n",
        " scheduler = KarrasVeScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"LMSDiscreteScheduler\":\n",
        " from  diffusers import LMSDiscreteScheduler\n",
        " scheduler = LMSDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerAncestralDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerAncestralDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revision, torch_dtype=torch_dtype ,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DPMSolverMultistepScheduler\":\n",
        " from  diffusers import DPMSolverMultistepScheduler\n",
        " scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã¸ç§»ã™\n",
        "#vae = vae.to(\"cuda\")\n",
        "#text_encoder = text_encoder.to(\"cuda\")\n",
        "#unet = unet.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Q0V08cQPSkk8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NSFWå›é¿,çœãƒ¡ãƒ¢ãƒªåŒ–,xformersæœ‰åŠ¹åŒ–\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "#â†“xformersã‚’ç„¡åŠ¹ã«ã—ãŸã„å ´åˆã¯æœ‰åŠ¹ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦å®Ÿè¡Œ    \n",
        "# pipe.disable_xformers_memory_efficient_attention"
      ],
      "metadata": {
        "id": "5FVy18G2Avxa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfmRXeVjGyJ"
      },
      "source": [
        "num_inference_stepsã¯1~200\n",
        "\n",
        "å›æ•°ãŒå¤šã„ç¨‹ç¶ºéº—ã«ãªã‚‹ãŒã€æ¥µç«¯ã«å¤§ããã—ã¦ã‚‚å¤‰ã‚ã‚‰ãªã„\n",
        "\n",
        "æ¨å¥¨å€¤ã¯50\n",
        "\n",
        "guidance_scaleã¯1~20\n",
        "\n",
        "æ•°å€¤ãŒå¤§ãã„ç¨‹Promptå†…å®¹ã«è¿‘ããªã‚‹ãŒå¤šæ§˜æ€§ãŒç„¡ããªã‚‹\n",
        "\n",
        "æ¨å¥¨å€¤ã¯7ã€œ8.5ãã‚‰ã„ã€30è¶…ãˆã‚‹ã¨ç ´ç¶»ã™ã‚‹\n",
        "\n",
        "batch_size å¢—ã‚„ã™ã¨æ–½è¡Œæ•°ãŒå¢—ãˆã‚‹?\n",
        "\n",
        "å®Ÿè¡Œé€Ÿåº¦ã‚‚ä¸ŠãŒã‚‹ãŒVRAMã‚’å¤§é‡ã«æ¶ˆè²»"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8tPqDxHJX9i",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title å¤‰æ•°ã®è¨­å®š\n",
        "\n",
        "#å¤‰æ•°å®£è¨€\n",
        "num_inference_steps = 50     #@param {type:\"number\"}      # Number of denoising steps\n",
        "guidance_scale = 7        #@param {type:\"number\"}       # Scale for classifier-free guidance\n",
        "#batch_size = 2 #@param {type:\"number\"}\n",
        "# ç”»åƒã®ã‚µã‚¤ã‚º 512*512ãŒåˆæœŸå€¤\n",
        "height = 512        #@param {type:\"number\"}              # default height of Stable Diffusion\n",
        "width = 512             #@param {type:\"number\"}          # default width of Stable Diffusion\n",
        "#batch_size = 1 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title æç”»æŒ‡ç¤º\n",
        "\n",
        "#å…¥åŠ›æ–‡å­— ã“ã“ã«å¥½ããªç¦å‰‡æ–‡å­—ã‚’ã„ã‚Œã¦ãã ã•ã„\n",
        "\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#ãƒã‚¬ãƒ†ã‚£ãƒ– é™¤å¤–ã—ãŸã„è¦ç´ ã‚’å…¥ã‚Œã‚‹\n",
        "\n",
        "negative_prompt = \"\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "gwE8DaQ24Z0M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j8-Yu00JGMA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ç”»åƒç”Ÿæˆå›æ•°ã¨SEEDã®ç¨®åˆ¥\n",
        "\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'}\n",
        "for i in range(N):\n",
        "# SEEDå€¤ã€ã“ã“ã‚’ã‹ãˆã‚‹ã¨ åŒã˜å…¥åŠ›æ–‡å­—ã§ã‚‚åˆ¥ã®ç”»åƒãŒã§ã¾ã™\n",
        "# seedã‚’å›ºå®šã™ã‚‹æ™‚ã¯seed_fixã«ãƒã‚§ãƒƒã‚¯\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "  #VRAMæ¶ˆè²»ã‚’æŠ‘ãˆãŸã„å ´åˆæœ‰åŠ¹ã«â†“ä½•æ•…ã‹diffuser 0.8.1ã«ã—ãŸã‚‰å‹•ã‹ãªã„\n",
        "    #pipe.enable_attention_slicing()\n",
        "    #pipe.enable_xformers_memory_efficient_attention()\n",
        "    with torch.no_grad():\n",
        "     with torch.inference_mode():\n",
        "     #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "      images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=20,generator = generator).images[0]\n",
        "    \n",
        "#ã©ã®SEEDå€¤ã§æç”»ã•ã‚ŒãŸã‹ç¢ºèªç”¨\n",
        "     print(\"SEED =\",seed)\n",
        "#ã©ã®schedulerã‚’ä½¿ã£ãŸã‹\n",
        "     #print(\"SCHEDULER =\",use_schedulers)\n",
        "     display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgw5A58WIkyc",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚„èª­è¾¼\n",
        "\n",
        "#Xformersã®å®Ÿè£…ã‚’ã—ãŸã„ã‘ã©ã‚ˆãã‚ã‹ã‚‰ã‚“ãª\n",
        "#!sudo docker run -it --gpus=all --ipc=host -v /home:/home nvcr.io/nvidia/pytorch:22.08-py3 bash\n",
        "#!pip install --pre torch\n",
        "#!pip install xformers pytorch_lightning numpy\n",
        "#!pip3 install triton\n",
        "#!git clone https://github.com/openai/triton.git\n",
        "#%cd triton/python/\n",
        "#!pip install -e .\n",
        "\n",
        "#!pip install pytorch_lightning\n",
        "# Then \n",
        "# !pip install git+https://github.com/facebookresearch/xformers@51dd119#egg=xformers\n",
        "\n",
        "# Followed by\n",
        "#!cd PATH_TO_DIFFUSER_FOLDER\n",
        "#!git checkout memory_efficient_attention\n",
        "#  !pip install -e . \n",
        "\n",
        "#import math\n",
        "#import os\n",
        "\n",
        "#import pytorch_lightning as pl\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "\n",
        "#from pytorch_lightning import Trainer, seed_everything\n",
        "#from pytorch_lightning.utilities import rank_zero_info\n",
        "#from torch.nn import functional as F\n",
        "#from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
        "\n",
        "#from xformers.factory.model_factory import xFormer, xFormerConfig\n",
        "\n",
        "#ã¨ã‚Šã‚ãˆãšã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã“ã‚Œå…¥ã‚Œã¨ãã‚ƒå‹•ãã‹ã‚‰ã„ã„ã‹\n",
        "#%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "if model == \"Stable Diffusion\":\n",
        " from diffusers import StableDiffusionPipeline #, {use_scheduler} #EulerAncestralDiscreteScheduler\n",
        "\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=YOUR_TOKEN\n",
        "# ).to(\"cuda\")\n",
        "\n",
        "# æ½œåœ¨ç©ºé–“ã‚’ç”»åƒç©ºé–“ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®VAEãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€\n",
        " vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\")\n",
        "# vae = AutoencoderKL.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"vae\")\n",
        "# æ½œåœ¨ç©ºé–“ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®U-Netãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®š\n",
        " unet = UNet2DConditionModel.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\") \n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"runwayml/stable-diffusion-v1-5\", scheduler=scheduler, torch_dtype=torch.float16 ,revision=\"fp16\", vae=vae,custom_pipeline=\"lpw_stable_diffusion\",\n",
        " ).to(\"cuda\")\n",
        "\n",
        "#NSFWå›é¿å‡¦ç†\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Normal\")\n",
        "\n",
        "elif model == \"Waifu Diffusion\":\n",
        " from diffusers import StableDiffusionPipeline,LMSDiscreteScheduler #DDIMScheduler\n",
        " vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"vae\")\n",
        "# vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion-v1-4/vae\")\n",
        " \n",
        " unet = UNet2DConditionModel.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"unet\")\n",
        "\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™ 1.3ã‹ã‚‰schedulerãŒå¤‰ã‚ã£ãŸã®ã§ã‚³ãƒ¡ãƒ³ãƒˆå‰ã®ã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "            \"hakurei/waifu-diffusion\",\n",
        "            custom_pipeline=\"lpw_stable_diffusion\",\n",
        "            torch_dtype=torch.float32,\n",
        "            #revision=\"fp16\",\n",
        "            #scheduler=DDIMScheduler\n",
        "            scheduler=LMSDiscreteScheduler(\n",
        "            beta_start=0.00085,\n",
        "            beta_end=0.012,\n",
        "            beta_schedule=\"scaled_linear\",\n",
        "            #clip_sample=False,\n",
        "            #set_alpha_to_one=False,\n",
        "            num_train_timesteps=1000\n",
        " ),\n",
        "            #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Waife\")\n",
        "\n",
        "elif model == \"Trinart Stable Diffusion\":\n",
        " from diffusers import StableDiffusionPipeline\n",
        " vae = AutoencoderKL.from_pretrained(\"naclbit/trinart_stable_diffusion_v2\", subfolder=\"vae\")\n",
        " unet = UNet2DConditionModel.from_pretrained(\"naclbit/trinart_stable_diffusion_v2\", subfolder=\"unet\")\n",
        "\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "      \"naclbit/trinart_stable_diffusion_v2\", \n",
        "      revision=\"diffusers-60k\",\n",
        "      #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart\")\n",
        "\n",
        "elif model == \"Trinart Waifu Stable Diffusion 50-50\":\n",
        " from diffusers import StableDiffusionPipeline\n",
        " vae = AutoencoderKL.from_pretrained(\"doohickey/trinart-waifu-diffusion-50-50\", subfolder=\"vae\")\n",
        " unet = UNet2DConditionModel.from_pretrained(\"doohickey/trinart-waifu-diffusion-50-50\", subfolder=\"unet\")\n",
        "\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"doohickey/trinart-waifu-diffusion-50-50\", \n",
        "      #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart-Waifu-50-50\")\n",
        "\n",
        "else:\n",
        " print(\"å…¥åŠ›ã‚¨ãƒ©ãƒ¼:æ•°å€¤ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã¸ç§»ã™\n",
        "vae = vae.to(\"cuda\")\n",
        "text_encoder = text_encoder.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06TWdF3JQaA"
      },
      "source": [
        "ã‚‚ã£ã¨è©³ã—ãçŸ¥ã‚ŠãŸã„äººã¯\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb#scrollTo=zHkHsdtnry57\n",
        "ã“ã£ã¡ã®ã¡ã‚ƒã‚“ã¨ã—ãŸcolabã‚’è¦‹ã‚‹ã‚“ã ï¼ï¼ï¼ï¼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhfQ4GLv39K3"
      },
      "source": [
        "# **â†“Waifuå˜ç‹¬å‹•ä½œ**\n",
        "ç¾çŠ¶Waifuã ã‘modelå¼•æ•°ã«revisionãŒç„¡ãã¦é¢å€’ãã•ã„ã®ã§ç‹¬ç«‹ã•ã›ãŸã€‚  \n",
        "ã“ã“ã‹ã‚‰å‹•ã‹ã›ã°è‰¯ã„ã€‚\n",
        "ç‰¹ã«2æ¬¡å…ƒã¯WifuãŒåœ§å€’çš„  \n",
        "~â€»NAIã«ã¯å½“ç„¶å¶ã‚ãªã„~  \n",
        "åˆæœŸã®schedulerã¯æ¨å¥¨ã®LMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye_11709e3Y0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " #@title Waifu Diffusionã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¨è¨­å®š\n",
        "!pip install -q diffusers==0.8.1 transformers scipy ftfy accelerate\n",
        "!pip install -q transformers scipy ftfy\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "\n",
        "#from transformers import CLIPTokenizer ,CLIPTextModel\n",
        "\n",
        "#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ã€tokenizerã¨ã€text_encoderã‚’èª­ã¿è¾¼ã‚€\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "\n",
        "#Xformersã®å®Ÿè£…ã‚’ã—ãŸã„ã‘ã©ã‚ˆãã‚ã‹ã‚‰ã‚“ãª\n",
        "# !sudo docker run -it --gpus=all --ipc=host -v /home:/home nvcr.io/nvidia/pytorch:22.08-py3 bash\n",
        "\n",
        "# Then \n",
        "# !pip install git+https://github.com/facebookresearch/xformers@51dd119#egg=xformers\n",
        "\n",
        "# Followed by\n",
        "# !cd PATH_TO_DIFFUSER_FOLDER\n",
        "# !git checkout memory_efficient_attention\n",
        "# !pip install -e . \n",
        "!git clone https://github.com/openai/triton.git\n",
        "%cd triton/python/\n",
        "!pip install -q -e .\n",
        "!pip3 install -q --upgrade triton\n",
        "!pip install -q pytorch_lightning\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "#!pip install pytorch_lightning\n",
        "#ã¨ã‚Šã‚ãˆãšã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ã“ã‚Œå…¥ã‚Œã¨ãã‚ƒå‹•ãã‹ã‚‰ã„ã„ã‹\n",
        "#!pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "#ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã—ãŸã„ã®ã§è¿½åŠ \n",
        "import random\n",
        "import torch\n",
        "\n",
        "from diffusers.models import AutoencoderKL\n",
        "from diffusers import UNet2DConditionModel\n",
        "\n",
        "from torch import autocast\n",
        "#from diffusers import DiffusionPipeline\n",
        " from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æº–å‚™\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\n",
        "#  \"hakurei/waifu-diffusion\",\n",
        "#  torch_dtype=torch.float32,\n",
        "  #revision=\"fp16\",#â†æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å»ƒæ­¢ã•ã‚Œã¦ã‚‹\n",
        "  #scheduler=DDIMScheduler(\n",
        "#vae = AutoencoderKL.from_pretrained(\"waifu-diffusion-v1-4/vae/kl-f8-anime.ckpt\")â†ä»® 1.4ãƒªãƒªãƒ¼ã‚¹æ™‚ã«ç¢ºèª\n",
        "vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"vae\")\n",
        "unet = UNet2DConditionModel.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"unet\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'hakurei/waifu-diffusion',   \n",
        "    custom_pipeline=\"lpw_stable_diffusion\",\n",
        "    #revision=\"fp32\",\n",
        "    torch_dtype=torch.float32,#vae=vae,\n",
        "  scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #.clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " vae = vae.to(\"cuda\")\n",
        "# text_encoder = text_encoder.to(\"cuda\")\n",
        " unet = unet.to(\"cuda\")\n",
        "#NSFWå›é¿å‡¦ç†\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "#VRAMä½æ¶ˆè²»â€»å°‘ã—å®Ÿè¡Œé€Ÿåº¦ãŒè½ã¡ã‚‹\n",
        "#pipe.enable_attention_slicing()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®é¸æŠ\n",
        "#@markdown ãŸã ã—ã€DDPM,KarrasVeã¯ç”»åƒå‡ºåŠ›å‡¦ç†ãŒå¿…è¦ãªã®ã‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å€‹åˆ¥è¨­å®šã—ãªã„ã¨ã„ã‘ãªã„ã®ã‹çŸ¥ã‚‰ã‚“ã‘ã©å‹•ã‹ãªã„\n",
        "use_schedulers = \"\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"KarrasVeScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\"]\n",
        "#use_scheduler å°†æ¥ä½¿ã†ã‹ã‚‚? schedulerã®æŒ‡å®šç”¨å¤‰æ•°ã«ã™ã‚‹ã¤ã‚‚ã‚Š\n",
        "##!kill -9 $(lsof -t)\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "\n",
        "model_id = \"hakurei/waifu-diffusion\"\n",
        "#revision = \"fp32\"\n",
        "torch_dtype = torch.float32\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
        "\n",
        "#ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚ºã¨ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ç”¨ã«ã€tokenizerã¨ã€text_encoderã‚’èª­ã¿è¾¼ãŸ\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã¸ç§»ã™\n",
        "vae = vae.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")\n",
        "\n",
        "# ãƒã‚¤ã‚ºã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®æŒ‡å®š\n",
        "if use_schedulers == \"DDIMScheduler\":\n",
        " from  diffusers import DDIMScheduler\n",
        " scheduler = DDIMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DDPMScheduler\":\n",
        " from  diffusers import DDPMScheduler\n",
        " scheduler = DDPMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"KarrasVeScheduler\":\n",
        " from  diffusers import KarrasVeScheduler\n",
        " scheduler = KarrasVeScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"LMSDiscreteScheduler\":\n",
        " from  diffusers import LMSDiscreteScheduler\n",
        " scheduler = LMSDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerAncestralDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerAncestralDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DPMSolverMultistepScheduler\":\n",
        " from  diffusers import DPMSolverMultistepScheduler\n",
        " scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã‚’GPUã¸ç§»ã™\n",
        "#vae = vae.to(\"cuda\")\n",
        "#text_encoder = text_encoder.to(\"cuda\")\n",
        "#unet = unet.to(\"cuda\")\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "#â†“xformersã‚’ç„¡åŠ¹ã«ã—ãŸã„å ´åˆã¯æœ‰åŠ¹ã‚³ãƒãƒ³ãƒ‰ã‚’ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦å®Ÿè¡Œ    \n",
        "# pipe.disable_xformers_memory_efficient_attention"
      ],
      "metadata": {
        "id": "pDx_qVEDrmLw",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTIRKLa_yfl"
      },
      "source": [
        "GUIã§ãªãCUIã§å‹•ãã‚ˆã†ã«ç›´ã—ãŸã€‚\n",
        "ãƒ«ãƒ¼ãƒ—çµ„ã‚“ã§æŒ‡å®šã—ãŸå›æ•°å®Ÿè¡Œã—ç¶šã‘ã‚‹ã®ã§ã“ã£ã¡ã®ã»ã†ãŒä½¿ã„å‹æ‰‹ã‚ˆã„ã€‚\n",
        "ãƒ©ãƒ³ã‚¿ã‚¤ãƒ åˆ‡æ–­ã§ã‚‚å†èµ·å‹•å¾Œç¶™ç¶šã™ã‚‹ã€‚"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_inference_stepsã¯1~200\n",
        "\n",
        "å›æ•°ãŒå¤šã„ç¨‹ç¶ºéº—ã«ãªã‚‹ãŒã€æ¥µç«¯ã«å¤§ããã—ã¦ã‚‚å¤‰ã‚ã‚‰ãªã„\n",
        "\n",
        "æ¨å¥¨å€¤ã¯50\n",
        "\n",
        "guidance_scaleã¯1~20\n",
        "\n",
        "æ•°å€¤ãŒå¤§ãã„ç¨‹Promptå†…å®¹ã«è¿‘ããªã‚‹ãŒå¤šæ§˜æ€§ãŒç„¡ããªã‚‹\n",
        "\n",
        "æ¨å¥¨å€¤ã¯7ã€œ8.5ãã‚‰ã„ã€30è¶…ãˆã‚‹ã¨ç ´ç¶»ã™ã‚‹\n",
        "\n",
        "batch_size å¢—ã‚„ã™ã¨æ–½è¡Œæ•°ãŒå¢—ãˆã‚‹?\n",
        "\n",
        "å®Ÿè¡Œé€Ÿåº¦ã‚‚ä¸ŠãŒã‚‹ãŒVRAMã‚’å¤§é‡ã«æ¶ˆè²»\n",
        "\n",
        "åŸºæœ¬çš„ã«ã¯512Ã—512ãŒ1ç•ªè‰¯ã„çµæœãŒå‡ºã‚‹\n",
        "\n",
        "guidance_scale 1~30 å¤§ãã„ç¨‹promptã«è¿‘ã„ç”»åƒã«ãªã‚‹ãŒå¤šæ§˜æ€§ã¯ç„¡ããªã‚‹"
      ],
      "metadata": {
        "id": "YDOetnwC1w1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title å¤‰æ•°ã®è¨­å®š\n",
        "\n",
        "#å¤‰æ•° åˆæœŸå€¤ 512*512 scale:6 step:50\n",
        "height = 768 #@param {type:\"number\"}\n",
        "width = 768 #@param {type:\"number\"}\n",
        "guidance_scale = 12 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "#batch_size = 1 #@param {type:\"number\"}\n",
        "#num_samples = 1 ã“ã‚Œã¯ [prompt] * num_samplesã§å…¥ã‚Œå­ã«æŒ‡å®šå›æ•°åˆ†å‡ºåŠ›"
      ],
      "metadata": {
        "id": "gPL1RDhR0X_8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title æç”»æŒ‡ç¤º\n",
        "prompt = \"((Masterpiece)),watercolor,pastel colors,1girl,solo ,pov,lying on back,from above,pastel colors,10yo,smelly,dog Ears mature female fluffy Dwarf,beautiful scarlet carl longhair,anus,Many pubic hair,Thick Thigh,huage ass,huage Breast,huage nipples,puffy nipples,spread legs ,squatting,spread pussy,pussy juice,cum on Breasts,Facial,1boy,her self insert veiny penis, sex ,hetero\" #@param {type:\"string\"}\n",
        "\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry,2girs,multiple girls,multiple pussy,multiple Crotches,multiple legs,multiple Thigh, Multiple vagina,The clitoris is a penis\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "LdLCkaac0sN_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dc8wK6oTpRt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "2#@title ãƒ«ãƒ¼ãƒ—å›æ•°Nã¨ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—æç”»æŒ‡ç¤º\n",
        "N = 5 #@param {type:\"number\"} \n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'} \n",
        "slice_size = \"\"\n",
        "#ãƒ«ãƒ¼ãƒ—å‡¦ç†\n",
        "for i in range(N):\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    with torch.inference_mode():\n",
        "    #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "     images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=20,generator = generator).images[0]\n",
        "\n",
        "#ã©ã®SEEDå€¤ã§æç”»ã•ã‚ŒãŸã‹ç¢ºèªç”¨\n",
        "     print(\"SEED =\",seed)\n",
        "     display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gdriveã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­è¾¼ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!python -m venv .env\n",
        "\n",
        "!source .env/bin/activate\n",
        "\n",
        "!pip install diffusers==0.7.1 transformers scipy ftfy accelerate\n",
        "!pip install --upgrade diffusers transformers scipy\n",
        "#!huggingface-cli login\n",
        "import torch\n",
        "from torch import autocast\n",
        "# secretAI\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "\n",
        "euler_ancestral_scheduler = EulerAncestralDiscreteScheduler.from_config(\"content/drive/MyDrive/model/novelAI.ckpt\", subfolder=\"scheduler\")\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    \"content/drive/MyDrive/model/novelAI.ckpt\",torch_dtype=torch.float16, custom_pipeline=\"lpw_stable_diffusion\", scheduler=euler_scheduler, use_auth_token=YOUR_TOKEN,\n",
        ")\n",
        "pipeline.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Z5cLeoAiY_fr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}