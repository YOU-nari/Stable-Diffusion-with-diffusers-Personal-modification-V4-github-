{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOU-nari/Stable-Diffusion-with-diffusers-Personal-modification-V4-github-/blob/main/stable_diffusion_with_diffusers_personal_modification_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pythonのバージョンを上げたい時だけ実行\n",
        "\n",
        "※現状は実行すると動かなくなる。\n",
        "\n",
        "将来使うかもしれないので一応追加しておく"
      ],
      "metadata": {
        "id": "odHVwbiCa0qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OSのバージョン確認\n",
        "!lsb_release -a"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xdqm5_4_PGFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonのバージョン・パス確認\n",
        "!echo $PYTHONPATH\n",
        "!python --version"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cyNINCcoP3pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 使いたいPythonのバージョンを指定\n",
        "targetPy:str=\"3.9\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "dzNPgYmsQPYi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaのインストール\n",
        "\n",
        "#@markdown [Minicondaのダウンロードページ](https://docs.conda.io/en/latest/miniconda.html)に行き、Linux用のインストーラの名前とURLを確認しておく。\n",
        "\n",
        "#@markdown 以下のセルに以下のように記載する（**空白厳禁**）\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "#@markdown - `MINOCONDA_INSTALLER`=`shファイル名`　（とりあえず、最新版）\n",
        "#@markdown - `MINICONDA_DOWNLOAD_HP`=`URL`\n",
        "\n",
        "#@markdown （最終確認：2021/7/3）\n",
        "%%bash\n",
        "MINICONDA_INSTALLER=Miniconda3-py39_4.12.0-Linux-x86_64.sh #@param {type:\"string\"}\n",
        "MINICONDA_DOWNLOAD_HP=https://repo.anaconda.com/miniconda #@param {type:\"string\"}\n",
        "\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget $MINICONDA_DOWNLOAD_HP/$MINICONDA_INSTALLER\n",
        "chmod +x $MINICONDA_INSTALLER\n",
        "./$MINICONDA_INSTALLER -b -f -p $MINICONDA_PREFIX"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eP7qf_T9Q5x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 以下のセルを実行して`conda バージョン`が表示されたらOK\n",
        "!conda -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n_mawP3gTJNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Minicondaをアップデート\n",
        "%%bash\n",
        "conda init bash\n",
        "conda update -n base -c defaults conda -y"
      ],
      "metadata": {
        "cellView": "form",
        "id": "L3OQSsqIUaBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pythonのバージョンを変更と確認\n",
        "!conda install python=$targetPy -y\n",
        "!python -V"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lNe9bX7SVuZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title インポートモジュールを検索させるために`sys.path`へパスを追加\n",
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python\"+targetPy+\"/site-packages\")\n",
        "sys.path"
      ],
      "metadata": {
        "cellView": "form",
        "id": "cW_OMoX5V86X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここまで"
      ],
      "metadata": {
        "id": "eWv5VLqzhbE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title colaboの残り時間確認\n",
        "!cat /proc/uptime | awk '{printf(\"残り時間 : %.2f\", 12-$1/60/60)}'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "z0RjMtSqhiUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpvjXRDm_QQq",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 利用可能なGPUとVRAMの確認\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PJ33S-Ktra"
      },
      "source": [
        "↑GPUが動く事確認してね     \n",
        "もし動いてない場合は ランタイムのタイプをGPUにしてね\n",
        "\n",
        "↓diffusersが更新されたら変更してね\n",
        "現時点最新\n",
        "diffusion:2.0\n",
        "diffuser:0.8.1\n",
        "Waifu:1.3\n",
        "trinart:v2\n",
        "\n",
        "現時点だとSD2.0はうまく動かない。\n",
        "なんか、色々バギーである。\n",
        "1.5を動かしてから2.0のモデルを読み込むと途中でコケるが使えるようにはなる。\n",
        "でも、微妙。修正待ちかな。  \n",
        "~diffusersあたりが対応するだろ(・д・)ﾁｯ~"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title HuggingFace🤗にログイン\n",
        "\n",
        "#markdown  https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "#from huggingface_hub import notebook_login\n",
        "#notebook_login()"
      ],
      "metadata": {
        "id": "ps9nDqIAWyxQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQEwlgJXKHmE",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Stable Diffusion diffusersをロード\n",
        "\n",
        "!pip install -q diffusers==0.8.1 transformers scipy ftfy accelerate\n",
        "!pip install -q transformers scipy ftfy\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "#!pip install -q huggingface_hub\n",
        "!pip install -q --upgrade git+https://github.com/huggingface/diffusers.git transformers accelerate scipy\n",
        "\n",
        "\n",
        "#!huggingface-cli login\n",
        "#自分のトークン記載 diffuser0.4.0からは1度ログ・インすれば不要らしい\n",
        "#YOUR_TOKEN=\"\"\n",
        "!git clone -q https://github.com/openai/triton.git\n",
        "%cd triton/python/\n",
        "!pip install -q -e .\n",
        "!pip3 install -q --upgrade triton\n",
        "!pip install -q pytorch_lightning\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 必要なmodule等のダウンロードと読み込み\n",
        "\n",
        "#from transformers import CLIPTokenizer ,CLIPTextModel\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import AutoencoderKL , UNet2DConditionModel , StableDiffusionPipeline\n",
        "\n",
        "#SEEDをランダム化したいので追加\n",
        "import random\n",
        "\n",
        "#ガベージコレクション用\n",
        "import gc"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZuQWrco6lPr2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title モデルを選ぶ\n",
        "\n",
        "#@markdown Stable Diffusionモデルを選択\n",
        "\n",
        "#@markdown Normal,Waife,Trinart,Trinart-Waife-50-50から選択\n",
        "model = \"\" #@param [\"\",\"Stable Diffusion\",\"Waifu Diffusion\",\"Trinart Stable Diffusion\",\"Trinart Waifu Stable Diffusion 50-50\"]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YWScX9Qcmgx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title スケジューラの選択\n",
        "#@markdown ただし、DDPM,KarrasVeは画像出力処理が必要なのかパラメータを個別設定しないといけないのか知らんけど動かない\n",
        "use_schedulers = \"\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"KarrasVeScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\"]\n",
        "#use_scheduler 将来使うかも? schedulerの指定用変数にするつもり\n",
        "#!kill -9 $(lsof -t)\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "if model == \"Stable Diffusion\":\n",
        " #model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        " model_id = \"stabilityai/stable-diffusion-2\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "elif model == \"Waifu Diffusion\":\n",
        " model_id = \"hakurei/waifu-diffusion\"\n",
        " revision = \"fp32\"\n",
        " torch_dtype = torch.float32\n",
        "elif model == \"Trinart Stable Diffusion\":\n",
        " model_id = \"naclbit/trinart_stable_diffusion_v2\"\n",
        " torch_dtype = torch.float16\n",
        " revision=\"diffusers-60k\"\n",
        "elif model == \"Trinart Waifu Stable Diffusion 50-50\":\n",
        " model_id = \"doohickey/trinart-waifu-diffusion-50-50\"\n",
        " revision = \"fp16\"\n",
        " torch_dtype = torch.float16\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
        "\n",
        "#トークナイズとテキストのエンコード用に、tokenizerと、text_encoderを読み込た\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
        "\n",
        "# モデルをGPUへ移す\n",
        "vae = vae.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")\n",
        "\n",
        "# ノイズスケジューラの指定\n",
        "if use_schedulers == \"DDIMScheduler\":\n",
        " from  diffusers import DDIMScheduler\n",
        " scheduler = DDIMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DDPMScheduler\":\n",
        " from  diffusers import DDPMScheduler\n",
        " scheduler = DDPMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"KarrasVeScheduler\":\n",
        " from  diffusers import KarrasVeScheduler\n",
        " scheduler = KarrasVeScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"LMSDiscreteScheduler\":\n",
        " from  diffusers import LMSDiscreteScheduler\n",
        " scheduler = LMSDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revison, torch_dtype=torch_dtype,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerAncestralDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerAncestralDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, revision=revision, torch_dtype=torch_dtype ,vae=vae ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DPMSolverMultistepScheduler\":\n",
        " from  diffusers import DPMSolverMultistepScheduler\n",
        " scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# モデルをGPUへ移す\n",
        "#vae = vae.to(\"cuda\")\n",
        "#text_encoder = text_encoder.to(\"cuda\")\n",
        "#unet = unet.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Q0V08cQPSkk8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NSFW回避,省メモリ化,xformers有効化\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "#↓xformersを無効にしたい場合は有効コマンドをコメントアウトして実行    \n",
        "# pipe.disable_xformers_memory_efficient_attention"
      ],
      "metadata": {
        "id": "5FVy18G2Avxa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGfmRXeVjGyJ"
      },
      "source": [
        "num_inference_stepsは1~200\n",
        "\n",
        "回数が多い程綺麗になるが、極端に大きくしても変わらない\n",
        "\n",
        "推奨値は50\n",
        "\n",
        "guidance_scaleは1~20\n",
        "\n",
        "数値が大きい程Prompt内容に近くなるが多様性が無くなる\n",
        "\n",
        "推奨値は7〜8.5くらい、30超えると破綻する\n",
        "\n",
        "batch_size 増やすと施行数が増える?\n",
        "\n",
        "実行速度も上がるがVRAMを大量に消費"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8tPqDxHJX9i",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 変数の設定\n",
        "\n",
        "#変数宣言\n",
        "num_inference_steps = 50     #@param {type:\"number\"}      # Number of denoising steps\n",
        "guidance_scale = 7        #@param {type:\"number\"}       # Scale for classifier-free guidance\n",
        "#batch_size = 2 #@param {type:\"number\"}\n",
        "# 画像のサイズ 512*512が初期値\n",
        "height = 512        #@param {type:\"number\"}              # default height of Stable Diffusion\n",
        "width = 512             #@param {type:\"number\"}          # default width of Stable Diffusion\n",
        "#batch_size = 1 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 描画指示\n",
        "\n",
        "#入力文字 ここに好きな禁則文字をいれてください\n",
        "\n",
        "prompt = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#ネガティブ 除外したい要素を入れる\n",
        "\n",
        "negative_prompt = \"\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "gwE8DaQ24Z0M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-j8-Yu00JGMA",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 画像生成回数とSEEDの種別\n",
        "\n",
        "N = 1 #@param {type:\"number\"}\n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'}\n",
        "for i in range(N):\n",
        "# SEED値、ここをかえると 同じ入力文字でも別の画像がでます\n",
        "# seedを固定する時はseed_fixにチェック\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "  #VRAM消費を抑えたい場合有効に↓何故かdiffuser 0.8.1にしたら動かない\n",
        "    #pipe.enable_attention_slicing()\n",
        "    #pipe.enable_xformers_memory_efficient_attention()\n",
        "    with torch.no_grad():\n",
        "     with torch.inference_mode():\n",
        "     #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "      images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=20,generator = generator).images[0]\n",
        "    \n",
        "#どのSEED値で描画されたか確認用\n",
        "     print(\"SEED =\",seed)\n",
        "#どのschedulerを使ったか\n",
        "     #print(\"SCHEDULER =\",use_schedulers)\n",
        "     display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgw5A58WIkyc",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title モデルデータのダウンロードや読込\n",
        "\n",
        "#Xformersの実装をしたいけどよくわからんな\n",
        "#!sudo docker run -it --gpus=all --ipc=host -v /home:/home nvcr.io/nvidia/pytorch:22.08-py3 bash\n",
        "#!pip install --pre torch\n",
        "#!pip install xformers pytorch_lightning numpy\n",
        "#!pip3 install triton\n",
        "#!git clone https://github.com/openai/triton.git\n",
        "#%cd triton/python/\n",
        "#!pip install -e .\n",
        "\n",
        "#!pip install pytorch_lightning\n",
        "# Then \n",
        "# !pip install git+https://github.com/facebookresearch/xformers@51dd119#egg=xformers\n",
        "\n",
        "# Followed by\n",
        "#!cd PATH_TO_DIFFUSER_FOLDER\n",
        "#!git checkout memory_efficient_attention\n",
        "#  !pip install -e . \n",
        "\n",
        "#import math\n",
        "#import os\n",
        "\n",
        "#import pytorch_lightning as pl\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "\n",
        "#from pytorch_lightning import Trainer, seed_everything\n",
        "#from pytorch_lightning.utilities import rank_zero_info\n",
        "#from torch.nn import functional as F\n",
        "#from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
        "\n",
        "#from xformers.factory.model_factory import xFormer, xFormerConfig\n",
        "\n",
        "#とりあえずコンパイル済みこれ入れときゃ動くからいいか\n",
        "#%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "if model == \"Stable Diffusion\":\n",
        " from diffusers import StableDiffusionPipeline #, {use_scheduler} #EulerAncestralDiscreteScheduler\n",
        "\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", use_auth_token=YOUR_TOKEN\n",
        "# ).to(\"cuda\")\n",
        "\n",
        "# 潜在空間を画像空間にデコードするためのVAEモデルを読み込む\n",
        " vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\")\n",
        "# vae = AutoencoderKL.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"vae\")\n",
        "# 潜在空間を生成するためのU-Netモデルの指定\n",
        " unet = UNet2DConditionModel.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\") \n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "     \"runwayml/stable-diffusion-v1-5\", scheduler=scheduler, torch_dtype=torch.float16 ,revision=\"fp16\", vae=vae,custom_pipeline=\"lpw_stable_diffusion\",\n",
        " ).to(\"cuda\")\n",
        "\n",
        "#NSFW回避処理\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Normal\")\n",
        "\n",
        "elif model == \"Waifu Diffusion\":\n",
        " from diffusers import StableDiffusionPipeline,LMSDiscreteScheduler #DDIMScheduler\n",
        " vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"vae\")\n",
        "# vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion-v1-4/vae\")\n",
        " \n",
        " unet = UNet2DConditionModel.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"unet\")\n",
        "\n",
        "# StableDiffusionパイプラインの準備 1.3からschedulerが変わったのでコメント前のはコメントアウト\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "            \"hakurei/waifu-diffusion\",\n",
        "            custom_pipeline=\"lpw_stable_diffusion\",\n",
        "            torch_dtype=torch.float32,\n",
        "            #revision=\"fp16\",\n",
        "            #scheduler=DDIMScheduler\n",
        "            scheduler=LMSDiscreteScheduler(\n",
        "            beta_start=0.00085,\n",
        "            beta_end=0.012,\n",
        "            beta_schedule=\"scaled_linear\",\n",
        "            #clip_sample=False,\n",
        "            #set_alpha_to_one=False,\n",
        "            num_train_timesteps=1000\n",
        " ),\n",
        "            #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Waife\")\n",
        "\n",
        "elif model == \"Trinart Stable Diffusion\":\n",
        " from diffusers import StableDiffusionPipeline\n",
        " vae = AutoencoderKL.from_pretrained(\"naclbit/trinart_stable_diffusion_v2\", subfolder=\"vae\")\n",
        " unet = UNet2DConditionModel.from_pretrained(\"naclbit/trinart_stable_diffusion_v2\", subfolder=\"unet\")\n",
        "\n",
        "# StableDiffusionパイプラインの準備\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "      \"naclbit/trinart_stable_diffusion_v2\", \n",
        "      revision=\"diffusers-60k\",\n",
        "      #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart\")\n",
        "\n",
        "elif model == \"Trinart Waifu Stable Diffusion 50-50\":\n",
        " from diffusers import StableDiffusionPipeline\n",
        " vae = AutoencoderKL.from_pretrained(\"doohickey/trinart-waifu-diffusion-50-50\", subfolder=\"vae\")\n",
        " unet = UNet2DConditionModel.from_pretrained(\"doohickey/trinart-waifu-diffusion-50-50\", subfolder=\"unet\")\n",
        "\n",
        "# StableDiffusionパイプラインの準備\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        \"doohickey/trinart-waifu-diffusion-50-50\", \n",
        "      #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " def dummy(images, **kwargs): return images, False\n",
        " pipe.safety_checker = dummy\n",
        " print(\"Model:Trinart-Waifu-50-50\")\n",
        "\n",
        "else:\n",
        " print(\"入力エラー:数値を見直してください。\")\n",
        "\n",
        "# モデルをGPUへ移す\n",
        "vae = vae.to(\"cuda\")\n",
        "text_encoder = text_encoder.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o06TWdF3JQaA"
      },
      "source": [
        "もっと詳しく知りたい人は\n",
        "https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb#scrollTo=zHkHsdtnry57\n",
        "こっちのちゃんとしたcolabを見るんだ！！！！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhfQ4GLv39K3"
      },
      "source": [
        "# **↓Waifu単独動作**\n",
        "現状Waifuだけmodel引数にrevisionが無くて面倒くさいので独立させた。  \n",
        "ここから動かせば良い。\n",
        "特に2次元はWifuが圧倒的  \n",
        "~※NAIには当然叶わない~  \n",
        "初期のschedulerは推奨のLMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye_11709e3Y0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        " #@title Waifu Diffusionのダウンロードと設定\n",
        "!pip install -q diffusers==0.8.1 transformers scipy ftfy accelerate\n",
        "!pip install -q transformers scipy ftfy\n",
        "!pip install -q --upgrade diffusers[torch]\n",
        "\n",
        "#from transformers import CLIPTokenizer ,CLIPTextModel\n",
        "\n",
        "#トークナイズとテキストのエンコード用に、tokenizerと、text_encoderを読み込む\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "\n",
        "#Xformersの実装をしたいけどよくわからんな\n",
        "# !sudo docker run -it --gpus=all --ipc=host -v /home:/home nvcr.io/nvidia/pytorch:22.08-py3 bash\n",
        "\n",
        "# Then \n",
        "# !pip install git+https://github.com/facebookresearch/xformers@51dd119#egg=xformers\n",
        "\n",
        "# Followed by\n",
        "# !cd PATH_TO_DIFFUSER_FOLDER\n",
        "# !git checkout memory_efficient_attention\n",
        "# !pip install -e . \n",
        "!git clone https://github.com/openai/triton.git\n",
        "%cd triton/python/\n",
        "!pip install -q -e .\n",
        "!pip3 install -q --upgrade triton\n",
        "!pip install -q pytorch_lightning\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "\n",
        "#!pip install pytorch_lightning\n",
        "#とりあえずコンパイル済みこれ入れときゃ動くからいいか\n",
        "#!pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "# These were compiled on Tesla T4, should also work on P100, thanks to https://github.com/metrolobo\n",
        "\n",
        "#ランダム化したいので追加\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from diffusers.models import AutoencoderKL\n",
        "from diffusers import UNet2DConditionModel\n",
        "\n",
        "from torch import autocast\n",
        "#from diffusers import DiffusionPipeline\n",
        " from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler #DDIMScheduler\n",
        "# StableDiffusionパイプラインの準備\n",
        "# pipe = StableDiffusionPipeline.from_pretrained(\n",
        "#  \"hakurei/waifu-diffusion\",\n",
        "#  torch_dtype=torch.float32,\n",
        "  #revision=\"fp16\",#←最新バージョンで廃止されてる\n",
        "  #scheduler=DDIMScheduler(\n",
        "#vae = AutoencoderKL.from_pretrained(\"waifu-diffusion-v1-4/vae/kl-f8-anime.ckpt\")←仮 1.4リリース時に確認\n",
        "vae = AutoencoderKL.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"vae\")\n",
        "unet = UNet2DConditionModel.from_pretrained(\"hakurei/waifu-diffusion\", subfolder=\"unet\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    'hakurei/waifu-diffusion',   \n",
        "    custom_pipeline=\"lpw_stable_diffusion\",\n",
        "    #revision=\"fp32\",\n",
        "    torch_dtype=torch.float32,#vae=vae,\n",
        "  scheduler=LMSDiscreteScheduler(\n",
        "         beta_start=0.00085,\n",
        "         beta_end=0.012,\n",
        "         beta_schedule=\"scaled_linear\",\n",
        "         #.clip_sample=False,\n",
        "         #set_alpha_to_one=False,\n",
        "         num_train_timesteps=1000\n",
        "     ),\n",
        "     #use_auth_token=YOUR_TOKEN\n",
        " ).to(\"cuda\")\n",
        " vae = vae.to(\"cuda\")\n",
        "# text_encoder = text_encoder.to(\"cuda\")\n",
        " unet = unet.to(\"cuda\")\n",
        "#NSFW回避処理\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "#VRAM低消費※少し実行速度が落ちる\n",
        "#pipe.enable_attention_slicing()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title スケジューラの選択\n",
        "#@markdown ただし、DDPM,KarrasVeは画像出力処理が必要なのかパラメータを個別設定しないといけないのか知らんけど動かない\n",
        "use_schedulers = \"\" #@param [\"\",\"DDIMScheduler\",\"DDPMScheduler\",\"KarrasVeScheduler\",\"LMSDiscreteScheduler\",\"EulerDiscreteScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverMultistepScheduler\"]\n",
        "#use_scheduler 将来使うかも? schedulerの指定用変数にするつもり\n",
        "##!kill -9 $(lsof -t)\n",
        "\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "\n",
        "model_id = \"hakurei/waifu-diffusion\"\n",
        "#revision = \"fp32\"\n",
        "torch_dtype = torch.float32\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(model_id, subfolder=\"vae\")\n",
        "\n",
        "#トークナイズとテキストのエンコード用に、tokenizerと、text_encoderを読み込た\n",
        "#tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "#text_encoder = CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "\n",
        "unet = UNet2DConditionModel.from_pretrained(model_id, subfolder=\"unet\")\n",
        "\n",
        "# モデルをGPUへ移す\n",
        "vae = vae.to(\"cuda\")\n",
        "unet = unet.to(\"cuda\")\n",
        "\n",
        "# ノイズスケジューラの指定\n",
        "if use_schedulers == \"DDIMScheduler\":\n",
        " from  diffusers import DDIMScheduler\n",
        " scheduler = DDIMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DDPMScheduler\":\n",
        " from  diffusers import DDPMScheduler\n",
        " scheduler = DDPMScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"KarrasVeScheduler\":\n",
        " from  diffusers import KarrasVeScheduler\n",
        " scheduler = KarrasVeScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"LMSDiscreteScheduler\":\n",
        " from  diffusers import LMSDiscreteScheduler\n",
        " scheduler = LMSDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"EulerAncestralDiscreteScheduler\":\n",
        " from  diffusers import EulerDiscreteScheduler\n",
        " scheduler = EulerAncestralDiscreteScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "elif use_schedulers == \"DPMSolverMultistepScheduler\":\n",
        " from  diffusers import DPMSolverMultistepScheduler\n",
        " scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
        " pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler, torch_dtype=torch_dtype ,custom_pipeline=\"lpw_stable_diffusion\")\n",
        " pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# モデルをGPUへ移す\n",
        "#vae = vae.to(\"cuda\")\n",
        "#text_encoder = text_encoder.to(\"cuda\")\n",
        "#unet = unet.to(\"cuda\")\n",
        "def dummy(images, **kwargs): return images, False\n",
        "pipe.safety_checker = dummy\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.enable_xformers_memory_efficient_attention()\n",
        "#↓xformersを無効にしたい場合は有効コマンドをコメントアウトして実行    \n",
        "# pipe.disable_xformers_memory_efficient_attention"
      ],
      "metadata": {
        "id": "pDx_qVEDrmLw",
        "collapsed": true,
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJTIRKLa_yfl"
      },
      "source": [
        "GUIでなくCUIで動くように直した。\n",
        "ループ組んで指定した回数実行し続けるのでこっちのほうが使い勝手よい。\n",
        "ランタイム切断でも再起動後継続する。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "num_inference_stepsは1~200\n",
        "\n",
        "回数が多い程綺麗になるが、極端に大きくしても変わらない\n",
        "\n",
        "推奨値は50\n",
        "\n",
        "guidance_scaleは1~20\n",
        "\n",
        "数値が大きい程Prompt内容に近くなるが多様性が無くなる\n",
        "\n",
        "推奨値は7〜8.5くらい、30超えると破綻する\n",
        "\n",
        "batch_size 増やすと施行数が増える?\n",
        "\n",
        "実行速度も上がるがVRAMを大量に消費\n",
        "\n",
        "基本的には512×512が1番良い結果が出る\n",
        "\n",
        "guidance_scale 1~30 大きい程promptに近い画像になるが多様性は無くなる"
      ],
      "metadata": {
        "id": "YDOetnwC1w1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 変数の設定\n",
        "\n",
        "#変数 初期値 512*512 scale:6 step:50\n",
        "height = 768 #@param {type:\"number\"}\n",
        "width = 768 #@param {type:\"number\"}\n",
        "guidance_scale = 12 #@param {type:\"number\"}\n",
        "num_inference_steps = 50 #@param {type:\"number\"}\n",
        "#batch_size = 1 #@param {type:\"number\"}\n",
        "#num_samples = 1 これは [prompt] * num_samplesで入れ子に指定回数分出力"
      ],
      "metadata": {
        "id": "gPL1RDhR0X_8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 描画指示\n",
        "prompt = \"((Masterpiece)),watercolor,pastel colors,1girl,solo ,pov,lying on back,from above,pastel colors,10yo,smelly,dog Ears mature female fluffy Dwarf,beautiful scarlet carl longhair,anus,Many pubic hair,Thick Thigh,huage ass,huage Breast,huage nipples,puffy nipples,spread legs ,squatting,spread pussy,pussy juice,cum on Breasts,Facial,1boy,her self insert veiny penis, sex ,hetero\" #@param {type:\"string\"}\n",
        "\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry,2girs,multiple girls,multiple pussy,multiple Crotches,multiple legs,multiple Thigh, Multiple vagina,The clitoris is a penis\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "id": "LdLCkaac0sN_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Dc8wK6oTpRt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "2#@title ループ回数Nとシードを設定し描画指示\n",
        "N = 5 #@param {type:\"number\"} \n",
        "seed = 1 #@param {type:\"number\"}\n",
        "seed_fix = False #@param {'type':'boolean'} \n",
        "slice_size = \"\"\n",
        "#ループ処理\n",
        "for i in range(N):\n",
        "   if seed_fix == True:\n",
        "    seed = seed\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   else:\n",
        "    seed = random.randrange(0, 2147483647, 1)\n",
        "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "   with autocast(\"cuda\"):\n",
        "    pipe.enable_attention_slicing()\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    with torch.inference_mode():\n",
        "    #images = pipe(prompt, height = height, width = width, guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,negative_prompt = negative_prompt, generator = generator).images\n",
        "     images = pipe.text2img(prompt, negative_prompt = negative_prompt, width = width,height = height,guidance_scale = guidance_scale, num_inference_steps = num_inference_steps,max_embeddings_multiples=20,generator = generator).images[0]\n",
        "\n",
        "#どのSEED値で描画されたか確認用\n",
        "     print(\"SEED =\",seed)\n",
        "     display(images)#.save(f'output{i}.png')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Gdriveからモデルデータを読込できるようにしたい\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!python -m venv .env\n",
        "\n",
        "!source .env/bin/activate\n",
        "\n",
        "!pip install diffusers==0.7.1 transformers scipy ftfy accelerate\n",
        "!pip install --upgrade diffusers transformers scipy\n",
        "#!huggingface-cli login\n",
        "import torch\n",
        "from torch import autocast\n",
        "# secretAI\n",
        "from diffusers import StableDiffusionPipeline, EulerAncestralDiscreteScheduler\n",
        "\n",
        "euler_ancestral_scheduler = EulerAncestralDiscreteScheduler.from_config(\"content/drive/MyDrive/model/novelAI.ckpt\", subfolder=\"scheduler\")\n",
        "pipeline = StableDiffusionPipeline.from_pretrained(\n",
        "    \"content/drive/MyDrive/model/novelAI.ckpt\",torch_dtype=torch.float16, custom_pipeline=\"lpw_stable_diffusion\", scheduler=euler_scheduler, use_auth_token=YOUR_TOKEN,\n",
        ")\n",
        "pipeline.to(\"cuda\")"
      ],
      "metadata": {
        "id": "Z5cLeoAiY_fr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}